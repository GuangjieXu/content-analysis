{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqCZhNLbDUlD"
      },
      "source": [
        "# Week 7 - Prediction & Causal Inference\n",
        "\n",
        "Last week, we explored (supervised) text classification, where we train a model to learn associations between text and some classification or value connected with it (e.g., what distinguishes a winning argument before the Supreme Court; can we extend our judgment regarding what documents are relevant to my thesis project to all of Google News; etc.) Classification often uses a representative sample of text about which we want to make inferences and then we use machine learning to learn \"true\" assignments and classify the rest.\n",
        "\n",
        "This week, we explore two different types of inferences to out-of-sample populations. _Prediction_ involves our reasoned expectation regarding an unobserved state of the world, given the world in which we live and on which we have trained our prediction algorithm. Often this prediction is about the future world. We don't expect the U.S. Congress to talk about the identical things today and tomorrow, but today should contain some useful information. by contrast _causal inference_ poses the related by distinct challenge of our reasoned expectations regarding an unobserved state of the world IF we intervene in some way. In other words, what does the intervention cause, and how can we predict it to change the world. Causality has a deeply contested history in social science and philosophy, but it usually involves an \"if,\" a difference between two counterfactual worlds, one where an event occurs and one where it doesn't.\n",
        "\n",
        "Causal questions in text analysis may place the text in one or more of many positions we explore below: as cause, effect, confounder, mediator (or moderator), or collider. For example, assuming that everything spoken can be transcribed into text, saying something mean might hurt someone's feelings (text as cause). Doing something mean might cause someone to say something angry (text as effect). Apologizing might change the influence of doing something mean (text as mediator/moderator). A compliment might obscure the effect of doing something mean (text as confounder). And yelling something audaciously mean might yield a loud, emotional response, which both influence the likelihood that the interaction was recorded and subjected to analysis (text as collider). As you can see, in a single conversation, text can play all of these roles. Why do we care about cause and effect with text? Because while words appear to exert power in the world, which words spoken under what circumstances by whom? Causal analysis attempts to get at the question, if _X_ was written or spoken, _Y_ would happen."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrjta8nQDybl",
        "outputId": "00c7096a-802b-45d3-84a7-4ce320e94a5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
            "  Cloning https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to /tmp/pip-req-build-06qrpcmz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git /tmp/pip-req-build-06qrpcmz\n",
            "  Resolved https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to commit b17a265d3b8253424e5b38872457f7437909a65d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.5.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.1.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (9.4.0)\n",
            "Requirement already satisfied: pdfminer2 in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (20151206)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.1.42)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.9.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.11.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.8.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (4.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.7.1)\n",
            "Requirement already satisfied: pyanno3 in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (2.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (4.12.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.20.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.34.46)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.25.1)\n",
            "Requirement already satisfied: speechrecognition in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.10.1)\n",
            "Requirement already satisfied: pysoundfile in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.9.0.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.19.3)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (7.34.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->lucem-illud==8.0.1) (2.5)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.46 in /usr/local/lib/python3.10/dist-packages (from boto3->lucem-illud==8.0.1) (1.34.46)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->lucem-illud==8.0.1) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->lucem-illud==8.0.1) (0.10.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->lucem-illud==8.0.1) (6.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython->lucem-illud==8.0.1) (4.0.11)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (4.66.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lucem-illud==8.0.1) (2023.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pdfminer2->lucem-illud==8.0.1) (1.16.0)\n",
            "Requirement already satisfied: traits in /usr/local/lib/python3.10/dist-packages (from pyanno3->lucem-illud==8.0.1) (6.4.3)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from pysoundfile->lucem-illud==8.0.1) (1.16.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->lucem-illud==8.0.1) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx->lucem-illud==8.0.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (2024.2.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lucem-illud==8.0.1) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (0.9.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.1.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->pysoundfile->lucem-illud==8.0.1) (2.21)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython->lucem-illud==8.0.1) (5.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->lucem-illud==8.0.1) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->lucem-illud==8.0.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->lucem-illud==8.0.1) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->lucem-illud==8.0.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->lucem-illud==8.0.1) (2.16.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->lucem-illud==8.0.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->lucem-illud==8.0.1) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->lucem-illud==8.0.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->lucem-illud==8.0.1) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "B31Wk5wrDUlH"
      },
      "outputs": [],
      "source": [
        "#Special module written for this class\n",
        "#This provides access to data and to helper functions from previous weeks\n",
        "#Make sure you update it before starting this notebook\n",
        "import lucem_illud #pip install -U git+https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
        "\n",
        "#All these packages need to be installed from pip\n",
        "import os #For managing the operating system\n",
        "import requests #For getting files\n",
        "import zipfile #For managing zips\n",
        "import numpy as np #For arrays\n",
        "import scipy as sp #For some stats\n",
        "import pandas as pd #Gives us DataFrames\n",
        "import numpy as np #Math and matrices\n",
        "import matplotlib.pyplot as plt #For graphics\n",
        "\n",
        "# statsmodels is a popular Python statistics package\n",
        "import statsmodels.api as sm\n",
        "# Let's also import its graphics module\n",
        "import statsmodels.graphics.api as smg\n",
        "# And the mediation module\n",
        "from statsmodels.stats.mediation import Mediation\n",
        "\n",
        "# Pipelines to add text-based quantiative variables for regressions\n",
        "from transformers import pipeline\n",
        "\n",
        "# We have a lot of features, so let's set Pandas to show all of them.\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc1Jc5DRDUlJ"
      },
      "source": [
        "# Prediction\n",
        "We can make predictions about a range of different text 'populations'. We can use texts in English to predict their translations in French. We can use newspaper articles from 2012 to 2022 to forecast the contents of 2023 newspaper articles (e.g., a [time series](https://en.wikipedia.org/wiki/Time_series)). Or we can \"nowcast\" by using real-time social information such as Tweets to predict when an important event is happening, such as a riot.\n",
        "\n",
        "If we don't have any information about how the new population will vary from the population we modeled, then prediction is implemented in the same way as in-sample inference. E.g., if you have a categorization of 2022 emails as spam or ham, you could predict whether 2023 emails are spam the same way you predicted 2022 emails. On the other hand, if you have new information, such as a trend beginning in December 2022 for spam emails to have \"Urgent:\" in the subject line, your 2023 prediction may differ by putting more weight on that indicator relative to others.\n",
        "\n",
        "In this way, prediction is similar to the classifications we performed last last week, incorporating multidimensional trends (e.g., time, place, source) learnable from your current corpus. We encourage you to think more about this if you are interested in predicting the future of your corpus!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEXRcCgUDUlK"
      },
      "source": [
        "## <font color=\"red\">*Exercise 1*</font>\n",
        "\n",
        "<font color=\"red\">Describe 2 separate predictions relevant to your project and associated texts, which involve predicting text that has not been observed based on patterns that have. Then, in a single, short paragraph, describe a research design through which you could use textual features and the tools of classification and regression to evaluate these predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to analyze the changes in Shanghai people's emotional tendencies regarding covid19 on Weibo, a social media. Two related prediction examples may include:\n",
        "\n",
        "Predict the impact of events on public sentiment: Based on historical data, predict the public sentiment tendencies that an upcoming event (such as policy changes, the end of the lockdown, etc.) may cause, such as predicting whether people’s general sentiment is support for the upcoming epidemic prevention policy (trust), worry (sadness), or disapproval (disgust).\n",
        "\n",
        "Predict the distribution of emotions under specific topics: analyze social media content under specific topics (such as epidemic prevention and control, etc.) and predict the distribution ratio of different emotions (joy, expectation, surprise, etc.) to understand the public's overall emotional response to the topic and Nuance.\n",
        "\n",
        "The research design can adopt the following methods: First, collect a large amount of text data related to the research topic, including but not limited to social media posts, news comments, forum discussions, etc. Use text preprocessing techniques (such as word segmentation, stop word removal) and feature extraction methods (such as TF-IDF, Word2Vec) to process these data and convert the text into a format that can be processed by the model. Then, use a classification model (such as the Transformer-based BERT model) to predict the emotional category of each text. Depending on project requirements, you may also need to use a regression model to predict changes in emotional intensity or emotional tendency. Improve prediction accuracy through cross-validation and model optimization. Finally, the prediction results are analyzed to explore the impact of different text features on emotional tendency prediction, as well as the application value of the prediction results in understanding public emotional dynamics and guiding public opinion management."
      ],
      "metadata": {
        "id": "BUc5ATiSwPl9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FAybWBJDUlL"
      },
      "source": [
        "# Text in causal inference\n",
        "\n",
        "In causal inference, we are interested in the effect of a _treatment_ on an _outcome_. There are five types of variables that could be directly involved in our causal model, and any could be a text variable. This figure from [Keith et al. 2020](https://aclanthology.org/2020.acl-main.474.pdf) concisely shows the five positions for variables in acyclic (i.e., no arrows flow back into themselves) causal inference: treatment, mediator, outcome, confounder, and collider.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" alt=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" style=\"width:500px\">\n",
        "\n",
        "\"Text as treatment\" means the effect of text on other variables. For example, how does the news coverage of a politician affect their election chance? How does the sentiment of a Reddit post affect its upvotes?\n",
        "\n",
        "Whether we're interested in text as treatment, mediator, outcome, or confounder, we have at our disposal the same causal inference strategies used with other forms of data, such as matching, difference in difference, regression discontinuity, and instrumental variables. Each of these methods usually gives you a more precise conditional identification of the causal influence than regressing an effect on a singular (purported) cause. For example, one of the readings for this week, [Saha 2019](https://doi.org/10.1145/3292522.3326032), uses propensity score matching, which is a straightforward method that works on most datasets (see Professor Gary King on [coarsened exact matching](https://www.youtube.com/watch?v=tvMyjDi4dyg)). For this assignment, we do not detail each of these causal strategies, but note several courses at UChicago that introduce these methods, as well as online textbooks (e.g., Scott Cunningham's [Causal Inference: The Mixtape](https://mixtape.scunning.com/)).\n",
        "\n",
        "You can do causal inference on any sort of text data as long as you have a plausible _identification_ strategy, meaning an argument that you can correctly identify a causal effect if one exists using your data and analysis. For example, if you have a data from a randomized controlled trial (RCT) where you intervene randomly with some treatment, you can identify a causal effect with relative ease. Text exhibits a wide array of dependencies making unconditional randomization impossible, but we will attempt strategies that approach it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRV5naW_DUlM"
      },
      "source": [
        "# Text as treatment and outcome\n",
        "\n",
        "To illustrate text as treatment and outcome, we will analyze a dataset of internet arguments. We have 8,895 pairs of comments, where one person makes a statement and the other responds. Our research question is thus: _How does the text of the first commenter affect the text of the respondent?_\n",
        "\n",
        "The data comes from the [Internet Argument Corpus](https://nlds.soe.ucsc.edu/iac). Let's load the data and take a look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs7qezmsDUlN",
        "outputId": "90228716-362b-4be8-a7d4-d5e95f37a436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded file: http://nldslab.soe.ucsc.edu/iac/iac_v1.1.zip\n"
          ]
        }
      ],
      "source": [
        "url = 'http://nldslab.soe.ucsc.edu/iac/iac_v1.1.zip'\n",
        "\n",
        "req = requests.get(url)\n",
        "\n",
        "filename = url.split('/')[-1]\n",
        "with open(filename,'wb') as output_file:\n",
        "    output_file.write(req.content)\n",
        "print('Downloaded file: ' + url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F6S99XfEDUlO",
        "outputId": "93d391dd-266b-4a87-914d-fd4308f0c3bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             key  discussion_id_x  agree-disagree  agreement  \\\n",
              "0       (731, 1)             6032        0.333333  -1.333333   \n",
              "1       (660, 3)            10217        0.600000   0.285714   \n",
              "2       (114, 5)             3462        0.600000  -1.500000   \n",
              "3        (43, 3)             9930        0.166667  -0.833333   \n",
              "4      (1314, 0)             5352        0.142857  -1.666667   \n",
              "...          ...              ...             ...        ...   \n",
              "9995    (580, 4)              821        0.800000  -2.000000   \n",
              "9997    (694, 4)             9258        0.000000  -3.200000   \n",
              "9998    (916, 6)            10301        0.000000  -3.000000   \n",
              "9999   (1348, 1)             6032        0.857143   0.800000   \n",
              "10000   (484, 0)             3426        0.142857  -2.833333   \n",
              "\n",
              "       agreement_unsure    attack  attack_unsure  defeater-undercutter  \\\n",
              "0              0.333333  0.333333       0.000000              0.500000   \n",
              "1              0.000000  0.714286       0.000000             -2.500000   \n",
              "2              0.000000  1.333333       0.000000              1.000000   \n",
              "3              0.333333  1.500000       0.000000              0.400000   \n",
              "4              0.166667  0.000000       0.166667             -1.166667   \n",
              "...                 ...       ...            ...                   ...   \n",
              "9995           0.166667 -0.500000       0.166667              1.000000   \n",
              "9997           0.200000  0.200000       0.200000             -1.800000   \n",
              "9998           0.000000 -2.400000       0.000000             -2.400000   \n",
              "9999           0.600000  0.600000       0.200000              3.000000   \n",
              "10000          0.166667  0.833333       0.166667             -1.000000   \n",
              "\n",
              "       defeater-undercutter_unsure  fact-feeling  fact-feeling_unsure  \\\n",
              "0                         0.000000      0.333333             0.333333   \n",
              "1                         0.000000      1.000000             0.000000   \n",
              "2                         0.000000      1.500000             0.000000   \n",
              "3                         0.000000      1.500000             0.166667   \n",
              "4                         0.166667     -0.833333             0.333333   \n",
              "...                            ...           ...                  ...   \n",
              "9995                      0.000000      1.333333             0.166667   \n",
              "9997                      0.000000      1.600000             0.400000   \n",
              "9998                      0.000000     -2.400000             0.000000   \n",
              "9999                      0.000000     -0.600000             0.400000   \n",
              "10000                     0.000000      0.833333             0.333333   \n",
              "\n",
              "       negotiate-attack  negotiate-attack_unsure  nicenasty  nicenasty_unsure  \\\n",
              "0              3.000000                 0.250000   0.666667          0.166667   \n",
              "1             -2.000000                 0.000000   1.142857          0.000000   \n",
              "2             -1.500000                 0.000000   2.166667          0.000000   \n",
              "3             -2.000000                 0.000000   1.666667          0.000000   \n",
              "4              0.833333                 0.333333   0.166667          0.166667   \n",
              "...                 ...                      ...        ...               ...   \n",
              "9995          -1.000000                 0.000000   0.500000          0.166667   \n",
              "9997          -1.200000                 0.200000   0.600000          0.200000   \n",
              "9998           2.800000                 0.000000  -2.400000          0.000000   \n",
              "9999          -3.000000                 0.000000   0.600000          0.200000   \n",
              "10000         -2.000000                 0.000000   1.500000          0.333333   \n",
              "\n",
              "       personal-audience  personal-audience_unsure  questioning-asserting  \\\n",
              "0              -2.250000                  0.250000              -4.250000   \n",
              "1              -1.500000                  0.000000               0.500000   \n",
              "2              -4.000000                  0.000000              -1.500000   \n",
              "3              -2.800000                  0.000000               0.000000   \n",
              "4              -3.333333                  0.166667              -0.166667   \n",
              "...                  ...                       ...                    ...   \n",
              "9995            0.000000                  0.000000               0.000000   \n",
              "9997           -1.600000                  0.000000               1.800000   \n",
              "9998           -4.200000                  0.000000               1.800000   \n",
              "9999            3.000000                  0.000000               3.000000   \n",
              "10000           2.333333                  0.000000               0.833333   \n",
              "\n",
              "       questioning-asserting_unsure   sarcasm  sarcasm_unsure  \\\n",
              "0                          0.000000  0.200000        0.166667   \n",
              "1                          0.000000  0.142857        0.000000   \n",
              "2                          0.000000  0.000000        0.000000   \n",
              "3                          0.000000  0.000000        0.000000   \n",
              "4                          0.166667  0.600000        0.166667   \n",
              "...                             ...       ...             ...   \n",
              "9995                       0.000000  0.200000        0.166667   \n",
              "9997                       0.000000  0.000000        0.200000   \n",
              "9998                       0.000000  0.000000        0.200000   \n",
              "9999                       0.000000  0.000000        0.200000   \n",
              "10000                      0.000000  0.000000        0.166667   \n",
              "\n",
              "       discussion_id_y  response_post_id  quote_post_id                  term  \\\n",
              "0                 6032            149609       149552.0                  None   \n",
              "1                10217            277697       277459.0                   yes   \n",
              "2                 3462             76012        75976.0  No terms in first 10   \n",
              "3                 9930            264824       264697.0                  well   \n",
              "4                 5352            128326       128325.0                   you   \n",
              "...                ...               ...            ...                   ...   \n",
              "9995               821             67788        67785.0                    oh   \n",
              "9997              9258            241951       241848.0                   but   \n",
              "9998             10301            281530       281509.0                  None   \n",
              "9999              6032            149609       149552.0  No terms in first 10   \n",
              "10000             3426             71284        71253.0  No terms in first 10   \n",
              "\n",
              "       task1 num annot  task2 num annot  task2 num disagree  \\\n",
              "0                    6                6                   4   \n",
              "1                    7                5                   2   \n",
              "2                    6                5                   2   \n",
              "3                    6                6                   5   \n",
              "4                    6                7                   6   \n",
              "...                ...              ...                 ...   \n",
              "9995                 6                5                   1   \n",
              "9997                 5                5                   5   \n",
              "9998                 5                5                   5   \n",
              "9999                 5                7                   1   \n",
              "10000                6                7                   6   \n",
              "\n",
              "                                                   quote  \\\n",
              "0      I remember looking at the classic evolutionary...   \n",
              "1      So they (pro-life peeps) say abortion is murde...   \n",
              "2      'If the solar system was brought about by an a...   \n",
              "3      ...to ToE because it means genetic evolution i...   \n",
              "4      Sir Issac Newton was an idiot and you are a ge...   \n",
              "...                                                  ...   \n",
              "9995   Why do some of you guys insist on being rabid ...   \n",
              "9997   But I see two people involved here. Whether th...   \n",
              "9998   I disagree with you because the logic you have...   \n",
              "9999   What I don't understand is why YEC's want to L...   \n",
              "10000  Perhaps also you might want to consider where ...   \n",
              "\n",
              "                                                response  \n",
              "0      Why do you find it necessary to fit observatio...  \n",
              "1      Yes, you are missing something. How come age d...  \n",
              "2      C.S.Lewis believes things on faith, yet we are...  \n",
              "3      Well, it might help if you could propose a mec...  \n",
              "4      You really think so? Im flattered, but I think...  \n",
              "...                                                  ...  \n",
              "9995   oh because for the past decade or so they have...  \n",
              "9997   But the embryo is a mere clump of flesh inside...  \n",
              "9998   **\\n Sez u. Your problem being that when you a...  \n",
              "9999     That's what faith does. It limits your options.  \n",
              "10000  On the contrary... These individuals (or indiv...  \n",
              "\n",
              "[8895 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f55dd2e2-556d-45a6-bcab-d248569f7463\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>discussion_id_x</th>\n",
              "      <th>agree-disagree</th>\n",
              "      <th>agreement</th>\n",
              "      <th>agreement_unsure</th>\n",
              "      <th>attack</th>\n",
              "      <th>attack_unsure</th>\n",
              "      <th>defeater-undercutter</th>\n",
              "      <th>defeater-undercutter_unsure</th>\n",
              "      <th>fact-feeling</th>\n",
              "      <th>fact-feeling_unsure</th>\n",
              "      <th>negotiate-attack</th>\n",
              "      <th>negotiate-attack_unsure</th>\n",
              "      <th>nicenasty</th>\n",
              "      <th>nicenasty_unsure</th>\n",
              "      <th>personal-audience</th>\n",
              "      <th>personal-audience_unsure</th>\n",
              "      <th>questioning-asserting</th>\n",
              "      <th>questioning-asserting_unsure</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>sarcasm_unsure</th>\n",
              "      <th>discussion_id_y</th>\n",
              "      <th>response_post_id</th>\n",
              "      <th>quote_post_id</th>\n",
              "      <th>term</th>\n",
              "      <th>task1 num annot</th>\n",
              "      <th>task2 num annot</th>\n",
              "      <th>task2 num disagree</th>\n",
              "      <th>quote</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(731, 1)</td>\n",
              "      <td>6032</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>-4.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>6032</td>\n",
              "      <td>149609</td>\n",
              "      <td>149552.0</td>\n",
              "      <td>None</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>I remember looking at the classic evolutionary...</td>\n",
              "      <td>Why do you find it necessary to fit observatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(660, 3)</td>\n",
              "      <td>10217</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10217</td>\n",
              "      <td>277697</td>\n",
              "      <td>277459.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>So they (pro-life peeps) say abortion is murde...</td>\n",
              "      <td>Yes, you are missing something. How come age d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(114, 5)</td>\n",
              "      <td>3462</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3462</td>\n",
              "      <td>76012</td>\n",
              "      <td>75976.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>'If the solar system was brought about by an a...</td>\n",
              "      <td>C.S.Lewis believes things on faith, yet we are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(43, 3)</td>\n",
              "      <td>9930</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9930</td>\n",
              "      <td>264824</td>\n",
              "      <td>264697.0</td>\n",
              "      <td>well</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>...to ToE because it means genetic evolution i...</td>\n",
              "      <td>Well, it might help if you could propose a mec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(1314, 0)</td>\n",
              "      <td>5352</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-1.666667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-3.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>5352</td>\n",
              "      <td>128326</td>\n",
              "      <td>128325.0</td>\n",
              "      <td>you</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>Sir Issac Newton was an idiot and you are a ge...</td>\n",
              "      <td>You really think so? Im flattered, but I think...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>(580, 4)</td>\n",
              "      <td>821</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>821</td>\n",
              "      <td>67788</td>\n",
              "      <td>67785.0</td>\n",
              "      <td>oh</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Why do some of you guys insist on being rabid ...</td>\n",
              "      <td>oh because for the past decade or so they have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>(694, 4)</td>\n",
              "      <td>9258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-1.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-1.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>9258</td>\n",
              "      <td>241951</td>\n",
              "      <td>241848.0</td>\n",
              "      <td>but</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>But I see two people involved here. Whether th...</td>\n",
              "      <td>But the embryo is a mere clump of flesh inside...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>(916, 6)</td>\n",
              "      <td>10301</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>10301</td>\n",
              "      <td>281530</td>\n",
              "      <td>281509.0</td>\n",
              "      <td>None</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>I disagree with you because the logic you have...</td>\n",
              "      <td>**\\n Sez u. Your problem being that when you a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>(1348, 1)</td>\n",
              "      <td>6032</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>6032</td>\n",
              "      <td>149609</td>\n",
              "      <td>149552.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>What I don't understand is why YEC's want to L...</td>\n",
              "      <td>That's what faith does. It limits your options.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>(484, 0)</td>\n",
              "      <td>3426</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-2.833333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>3426</td>\n",
              "      <td>71284</td>\n",
              "      <td>71253.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>Perhaps also you might want to consider where ...</td>\n",
              "      <td>On the contrary... These individuals (or indiv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8895 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f55dd2e2-556d-45a6-bcab-d248569f7463')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f55dd2e2-556d-45a6-bcab-d248569f7463 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f55dd2e2-556d-45a6-bcab-d248569f7463');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d55d2aa9-a349-4ee9-b0b8-f042a749a026\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d55d2aa9-a349-4ee9-b0b8-f042a749a026')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d55d2aa9-a349-4ee9-b0b8-f042a749a026 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_059c6009-462a-4722-9504-71ae7d6ec6e2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pairs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_059c6009-462a-4722-9504-71ae7d6ec6e2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pairs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "with zipfile.ZipFile('iac_v1.1.zip') as z:\n",
        "   with z.open('iac_v1.1/data/fourforums/annotations/mechanical_turk/qr_averages.csv') as f:\n",
        "      qr = pd.read_csv(f)\n",
        "\n",
        "   with z.open('iac_v1.1/data/fourforums/annotations/mechanical_turk/qr_meta.csv') as f:\n",
        "      md = pd.read_csv(f)\n",
        "\n",
        "# columns = ['key', 'nicenasty', 'questioning-asserting', 'negotiate-attack', 'fact-feeling']\n",
        "# qr_sub = qr[columns]\n",
        "# qr_sub = qr\n",
        "\n",
        "pairs = qr.merge(md, how='inner', on='key')\n",
        "pairs = pairs[~pairs.quote_post_id.isnull() & ~pairs.response_post_id.isnull()]\n",
        "pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YIiXk7jDUlP"
      },
      "source": [
        "Note that each comment and response were annotated by workers on Amazon Mechanical Turk, which we piloted last week. Variables like \"agree-disagree\" are the averages of annotations made by workers on Mechanical Turk on an 11-point Likert scale (-5 to 5) using a slider. Workers were asked questions, and then had the opportunity to note whether or not their were \"unsure\" about their assessment (Boolean - Y/N):\n",
        "\n",
        "* __agree/disagree__ (Boolean -- Y/N): Does the respondent agree (0) OR disagree (1) with the prior post?\n",
        "* __sarcasm__ (Boolean -- Y/N): Is the respondent using sarcasm (1 - Y; 0 - N)?\n",
        "* __fact/feeling__  (-5 to 5): Is the respondent attempting to make a fact based argument (-5) OR appealing to feelings and emotions (+5)?\n",
        "* __attack/insult__ (-5 to 5): Is the respondent being supportive/respectful (-5) OR are they attacking/insulting in their writing (+5)?\n",
        "* __nice/nasty__ (-5 to 5): Is the respondent attempting to be nice (-5) OR is their attitude fairly nasty (+5)?\n",
        "* __audience__ (-5 to 5): Is the respondent's arguments intended more to be interacting directly with the original poster (-5) OR with a wider audience (+5)?\n",
        "* __undercutting__ (-5 to 5): Is the argument of the respondent targeted at the entirety of the original poster's argument (-5) OR is the argument of the respondent targed at a more specific idea within the post (+5)?\n",
        "* __negotiate/attack__ (-5 to 5): Does the respondent seem to have an argument of their own (-5) OR is the respondent simply attacking the original poster's argument (+5)?\n",
        "* __question/assert__ (-5 to 5): Is the respondent questioning the original poster (-5) OR is the respondent asserting their own ideas (+5)?\n",
        "\n",
        "Unfortunately the dataset only has the \"response\" annotated, not the original \"quote.\" However, some \"responses\" in this dataset are also \"quotes,\" meaning we can form triples of quote-response-response. Let's self-merge this dataframe to get these \"r1\" and \"r2\" pairs where both texts have annotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F1OouWXhDUlQ",
        "outputId": "564ab36e-6795-4d7d-8436-a9579b5e0d0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  quote  \\\n",
              "0     I remember looking at the classic evolutionary...   \n",
              "1                              What is the fun in that?   \n",
              "2     First off, the scientific method goes:\\n \\n 1)...   \n",
              "3     You can ignore the obvious question. This is w...   \n",
              "4     Its really sad what these gay predator priests...   \n",
              "...                                                 ...   \n",
              "1341                      1. Did she do anything wrong?   \n",
              "1342  this is also the reason why atheism is more li...   \n",
              "1343  Assault weapons? first of all, what are assaul...   \n",
              "1344  And without a gun you're defenseless, why can'...   \n",
              "1345  What I don't understand is why YEC's want to L...   \n",
              "\n",
              "                                              response1  \\\n",
              "0     Why do you find it necessary to fit observatio...   \n",
              "1     Seriously? Well, I come here hoping for someth...   \n",
              "2     You guys know me. Always happy to correct anyo...   \n",
              "3     Actually what they are really doing is ignorin...   \n",
              "4     Homosexuals are attracted to adults of the sam...   \n",
              "...                                                 ...   \n",
              "1341  Yes, she walked down the wrong alley, alone. W...   \n",
              "1342  It is curious how lately christians have been ...   \n",
              "1343  Thanks Patriot for the well researched respons...   \n",
              "1344  Hardly any criminals go armed in England, and ...   \n",
              "1345    That's what faith does. It limits your options.   \n",
              "\n",
              "                                              response2  attack_r1  \\\n",
              "0     Evolution has no goals, it is merely a beautif...   0.333333   \n",
              "1     nah, I was just poking fun because I can! Pers...  -0.600000   \n",
              "2     Ah, thanks for the correction, although there ...   2.400000   \n",
              "3     Really, then show me how I'm wrong - without d...  -3.500000   \n",
              "4     Homosexuals are attracted to people of the sam...   0.166667   \n",
              "...                                                 ...        ...   \n",
              "1341  So it was wrong for her to walk down a public ...   0.166667   \n",
              "1342  Well, the type of atheism you are talking abou...   1.200000   \n",
              "1343  The ban on assault weapons stands on such polt...   2.000000   \n",
              "1344  All of the British papers keep going on about ...   2.400000   \n",
              "1345  Here's a nice little Google def: A convinced b...   0.600000   \n",
              "\n",
              "      fact-feeling_r1  nicenasty_r1  sarcasm_r1  agreement_r2     key_r1  \\\n",
              "0            0.333333      0.666667    0.200000     -2.833333   (731, 1)   \n",
              "1           -2.200000      0.000000    0.000000     -2.166667   (697, 2)   \n",
              "2            2.800000      2.200000    0.000000     -0.400000     (9, 0)   \n",
              "3           -3.166667     -3.166667    0.166667     -1.833333  (1077, 1)   \n",
              "4            2.166667     -0.166667    0.400000     -2.666667   (611, 0)   \n",
              "...               ...           ...         ...           ...        ...   \n",
              "1341         0.166667      0.500000    0.333333     -3.333333    (27, 4)   \n",
              "1342         0.800000      0.600000    0.250000     -2.250000  (1382, 6)   \n",
              "1343         2.000000      2.500000    0.000000      0.200000   (897, 4)   \n",
              "1344         2.000000      2.600000    0.000000     -2.800000  (1231, 1)   \n",
              "1345        -0.600000      0.600000    0.000000     -2.400000  (1348, 1)   \n",
              "\n",
              "      discussion_id_x_r1  agree-disagree_r1  agreement_r1  \\\n",
              "0                   6032           0.333333     -1.333333   \n",
              "1                   5205           0.833333     -2.400000   \n",
              "2                   9449           0.400000      0.600000   \n",
              "3                   3467           0.400000     -4.333333   \n",
              "4                   4337           0.333333     -2.000000   \n",
              "...                  ...                ...           ...   \n",
              "1341               13306           0.800000      0.666667   \n",
              "1342                3982           0.000000     -1.000000   \n",
              "1343                  50           0.833333      0.500000   \n",
              "1344               11999           0.285714     -1.600000   \n",
              "1345                6032           0.857143      0.800000   \n",
              "\n",
              "      agreement_unsure_r1  attack_unsure_r1  defeater-undercutter_r1  \\\n",
              "0                0.333333          0.000000                 0.500000   \n",
              "1                0.000000          0.000000                -5.000000   \n",
              "2                0.200000          0.200000                -2.666667   \n",
              "3                0.000000          0.000000                -4.666667   \n",
              "4                0.166667          0.166667                -0.750000   \n",
              "...                   ...               ...                      ...   \n",
              "1341             0.166667          0.166667                 0.000000   \n",
              "1342             0.200000          0.200000                -1.285714   \n",
              "1343             0.000000          0.000000                 1.000000   \n",
              "1344             0.000000          0.000000                 1.200000   \n",
              "1345             0.600000          0.200000                 3.000000   \n",
              "\n",
              "      defeater-undercutter_unsure_r1  fact-feeling_unsure_r1  \\\n",
              "0                                0.0                0.333333   \n",
              "1                                0.0                0.000000   \n",
              "2                                0.0                0.200000   \n",
              "3                                0.0                0.000000   \n",
              "4                                0.0                0.166667   \n",
              "...                              ...                     ...   \n",
              "1341                             0.0                0.166667   \n",
              "1342                             0.0                0.200000   \n",
              "1343                             0.0                0.000000   \n",
              "1344                             0.0                0.000000   \n",
              "1345                             0.0                0.400000   \n",
              "\n",
              "      negotiate-attack_r1  negotiate-attack_unsure_r1  nicenasty_unsure_r1  \\\n",
              "0                3.000000                        0.25             0.166667   \n",
              "1                2.000000                        0.00             0.000000   \n",
              "2               -3.666667                        0.00             0.200000   \n",
              "3               -0.666667                        0.00             0.000000   \n",
              "4               -2.000000                        0.00             0.166667   \n",
              "...                   ...                         ...                  ...   \n",
              "1341            -1.000000                        0.00             0.166667   \n",
              "1342            -0.428571                        0.00             0.200000   \n",
              "1343             1.000000                        0.00             0.000000   \n",
              "1344            -1.000000                        0.00             0.000000   \n",
              "1345            -3.000000                        0.00             0.200000   \n",
              "\n",
              "      personal-audience_r1  personal-audience_unsure_r1  \\\n",
              "0                -2.250000                         0.25   \n",
              "1                 0.000000                         0.00   \n",
              "2                 0.333333                         0.00   \n",
              "3                -2.000000                         0.00   \n",
              "4                 0.000000                         0.00   \n",
              "...                    ...                          ...   \n",
              "1341              0.000000                         0.00   \n",
              "1342              0.857143                         0.00   \n",
              "1343              4.000000                         0.00   \n",
              "1344              0.000000                         0.00   \n",
              "1345              3.000000                         0.00   \n",
              "\n",
              "      questioning-asserting_r1  questioning-asserting_unsure_r1  \\\n",
              "0                    -4.250000                              0.0   \n",
              "1                    -2.000000                              0.0   \n",
              "2                     3.666667                              0.0   \n",
              "3                     3.000000                              0.0   \n",
              "4                     3.750000                              0.0   \n",
              "...                        ...                              ...   \n",
              "1341                  0.000000                              0.0   \n",
              "1342                  1.714286                              0.0   \n",
              "1343                  1.000000                              0.0   \n",
              "1344                 -0.200000                              0.0   \n",
              "1345                  3.000000                              0.0   \n",
              "\n",
              "      sarcasm_unsure_r1  discussion_id_y_r1  response_post_id_r1  \\\n",
              "0              0.166667                6032               149609   \n",
              "1              0.000000                5205               122800   \n",
              "2              0.200000                9449               247240   \n",
              "3              0.000000                3467                73741   \n",
              "4              0.166667                4337               112008   \n",
              "...                 ...                 ...                  ...   \n",
              "1341           0.500000               13306               370461   \n",
              "1342           0.200000                3982                83610   \n",
              "1343           0.000000                  50                33286   \n",
              "1344           0.000000               11999               333578   \n",
              "1345           0.200000                6032               149609   \n",
              "\n",
              "      quote_post_id_r1               term_r1  task1 num annot_r1  \\\n",
              "0             149552.0                  None                   6   \n",
              "1             122780.0                  None                   5   \n",
              "2             247225.0                   you                   5   \n",
              "3              73738.0              actually                   6   \n",
              "4             111931.0  No terms in first 10                   6   \n",
              "...                ...                   ...                 ...   \n",
              "1341          370385.0                   yes                   6   \n",
              "1342           83594.0  No terms in first 10                   5   \n",
              "1343             173.0                  None                   4   \n",
              "1344          333574.0                  None                   5   \n",
              "1345          149552.0  No terms in first 10                   5   \n",
              "\n",
              "      task2 num annot_r1  task2 num disagree_r1     key_r2  \\\n",
              "0                      6                      4   (610, 2)   \n",
              "1                      6                      1  (1267, 0)   \n",
              "2                      5                      3  (1393, 1)   \n",
              "3                      5                      3   (622, 1)   \n",
              "4                      6                      4  (1350, 0)   \n",
              "...                  ...                    ...        ...   \n",
              "1341                   5                      1    (83, 5)   \n",
              "1342                   7                      7   (974, 6)   \n",
              "1343                   6                      1   (398, 4)   \n",
              "1344                   7                      5  (1393, 2)   \n",
              "1345                   7                      1   (402, 2)   \n",
              "\n",
              "      discussion_id_x_r2  agree-disagree_r2  agreement_unsure_r2  attack_r2  \\\n",
              "0                   6032           0.600000             0.166667   0.333333   \n",
              "1                   5205           0.600000             0.333333   0.833333   \n",
              "2                   9449           1.000000             0.200000   0.800000   \n",
              "3                   3467           0.600000             0.166667  -1.333333   \n",
              "4                   4337           0.428571             0.000000   1.166667   \n",
              "...                  ...                ...                  ...        ...   \n",
              "1341               13306           0.200000             0.166667  -3.166667   \n",
              "1342                3982           0.600000             0.250000   0.750000   \n",
              "1343                  50           0.000000             0.600000   2.200000   \n",
              "1344               11999           0.571429             0.200000   0.200000   \n",
              "1345                6032           0.428571             0.200000   1.000000   \n",
              "\n",
              "      attack_unsure_r2  defeater-undercutter_r2  \\\n",
              "0             0.166667                    -3.50   \n",
              "1             0.166667                    -1.50   \n",
              "2             0.200000                      NaN   \n",
              "3             0.166667                     2.50   \n",
              "4             0.000000                    -2.50   \n",
              "...                ...                      ...   \n",
              "1341          0.166667                    -2.75   \n",
              "1342          0.250000                     2.50   \n",
              "1343          0.400000                    -2.60   \n",
              "1344          0.200000                    -3.00   \n",
              "1345          0.000000                    -0.25   \n",
              "\n",
              "      defeater-undercutter_unsure_r2  fact-feeling_r2  fact-feeling_unsure_r2  \\\n",
              "0                                0.0         1.333333                0.166667   \n",
              "1                                0.0        -1.333333                0.500000   \n",
              "2                                NaN         1.200000                0.200000   \n",
              "3                                0.0         0.333333                0.166667   \n",
              "4                                0.0         0.666667                0.000000   \n",
              "...                              ...              ...                     ...   \n",
              "1341                             0.0        -3.500000                0.166667   \n",
              "1342                             0.0         1.000000                0.250000   \n",
              "1343                             0.0         1.800000                0.400000   \n",
              "1344                             0.0         0.400000                0.200000   \n",
              "1345                             0.0         0.600000                0.000000   \n",
              "\n",
              "      negotiate-attack_r2  negotiate-attack_unsure_r2  nicenasty_r2  \\\n",
              "0                3.500000                         0.0      0.500000   \n",
              "1                2.000000                         0.0      0.500000   \n",
              "2                     NaN                         NaN      1.000000   \n",
              "3                1.500000                         0.0      0.000000   \n",
              "4               -1.750000                         0.0      1.166667   \n",
              "...                   ...                         ...           ...   \n",
              "1341             1.500000                         0.0     -2.666667   \n",
              "1342            -3.000000                         0.0      1.750000   \n",
              "1343            -1.200000                         0.0      1.200000   \n",
              "1344            -0.333333                         0.0      0.200000   \n",
              "1345            -3.000000                         0.0      1.200000   \n",
              "\n",
              "      nicenasty_unsure_r2  personal-audience_r2  personal-audience_unsure_r2  \\\n",
              "0                0.333333             -4.000000                          0.0   \n",
              "1                0.166667             -3.000000                          0.0   \n",
              "2                0.400000                   NaN                          NaN   \n",
              "3                0.166667              0.000000                          0.0   \n",
              "4                0.000000             -1.250000                          0.0   \n",
              "...                   ...                   ...                          ...   \n",
              "1341             0.166667             -2.250000                          0.0   \n",
              "1342             0.250000             -3.000000                          0.0   \n",
              "1343             0.400000             -0.800000                          0.0   \n",
              "1344             0.200000             -2.666667                          0.0   \n",
              "1345             0.000000             -0.500000                          0.0   \n",
              "\n",
              "      questioning-asserting_r2  questioning-asserting_unsure_r2  sarcasm_r2  \\\n",
              "0                     1.500000                              0.0         0.0   \n",
              "1                    -1.500000                              0.0         0.2   \n",
              "2                          NaN                              NaN         0.0   \n",
              "3                    -1.500000                              0.0         0.2   \n",
              "4                     3.250000                              0.0         0.0   \n",
              "...                        ...                              ...         ...   \n",
              "1341                 -0.750000                              0.0         0.2   \n",
              "1342                  2.500000                              0.0         0.0   \n",
              "1343                  2.000000                              0.0         0.0   \n",
              "1344                 -0.333333                              0.0         0.0   \n",
              "1345                  3.250000                              0.0         0.2   \n",
              "\n",
              "      sarcasm_unsure_r2  discussion_id_y_r2  response_post_id_r2  \\\n",
              "0              0.166667                6032               149673   \n",
              "1              0.166667                5205               123129   \n",
              "2              0.400000                9449               247243   \n",
              "3              0.166667                3467                73783   \n",
              "4              0.000000                4337               112012   \n",
              "...                 ...                 ...                  ...   \n",
              "1341           0.166667               13306               370646   \n",
              "1342           0.000000                3982                83636   \n",
              "1343           0.200000                  50                33347   \n",
              "1344           0.400000               11999               333583   \n",
              "1345           0.000000                6032               149673   \n",
              "\n",
              "      quote_post_id_r2               term_r2  task1 num annot_r2  \\\n",
              "0             149609.0                  None                   6   \n",
              "1             122800.0                  None                   6   \n",
              "2             247240.0  No terms in first 10                   5   \n",
              "3              73741.0                really                   6   \n",
              "4             112008.0  No terms in first 10                   6   \n",
              "...                ...                   ...                 ...   \n",
              "1341          370461.0                    so                   6   \n",
              "1342           83610.0                  well                   4   \n",
              "1343           33286.0  No terms in first 10                   5   \n",
              "1344          333578.0  No terms in first 10                   5   \n",
              "1345          149609.0  No terms in first 10                   5   \n",
              "\n",
              "      task2 num annot_r2  task2 num disagree_r2  \n",
              "0                      5                      2  \n",
              "1                      5                      2  \n",
              "2                      7                      0  \n",
              "3                      5                      2  \n",
              "4                      7                      4  \n",
              "...                  ...                    ...  \n",
              "1341                   5                      4  \n",
              "1342                   5                      2  \n",
              "1343                   5                      5  \n",
              "1344                   7                      3  \n",
              "1345                   7                      4  \n",
              "\n",
              "[1340 rows x 59 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b5f146c-405b-469f-a54e-65c14419f824\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>response1</th>\n",
              "      <th>response2</th>\n",
              "      <th>attack_r1</th>\n",
              "      <th>fact-feeling_r1</th>\n",
              "      <th>nicenasty_r1</th>\n",
              "      <th>sarcasm_r1</th>\n",
              "      <th>agreement_r2</th>\n",
              "      <th>key_r1</th>\n",
              "      <th>discussion_id_x_r1</th>\n",
              "      <th>agree-disagree_r1</th>\n",
              "      <th>agreement_r1</th>\n",
              "      <th>agreement_unsure_r1</th>\n",
              "      <th>attack_unsure_r1</th>\n",
              "      <th>defeater-undercutter_r1</th>\n",
              "      <th>defeater-undercutter_unsure_r1</th>\n",
              "      <th>fact-feeling_unsure_r1</th>\n",
              "      <th>negotiate-attack_r1</th>\n",
              "      <th>negotiate-attack_unsure_r1</th>\n",
              "      <th>nicenasty_unsure_r1</th>\n",
              "      <th>personal-audience_r1</th>\n",
              "      <th>personal-audience_unsure_r1</th>\n",
              "      <th>questioning-asserting_r1</th>\n",
              "      <th>questioning-asserting_unsure_r1</th>\n",
              "      <th>sarcasm_unsure_r1</th>\n",
              "      <th>discussion_id_y_r1</th>\n",
              "      <th>response_post_id_r1</th>\n",
              "      <th>quote_post_id_r1</th>\n",
              "      <th>term_r1</th>\n",
              "      <th>task1 num annot_r1</th>\n",
              "      <th>task2 num annot_r1</th>\n",
              "      <th>task2 num disagree_r1</th>\n",
              "      <th>key_r2</th>\n",
              "      <th>discussion_id_x_r2</th>\n",
              "      <th>agree-disagree_r2</th>\n",
              "      <th>agreement_unsure_r2</th>\n",
              "      <th>attack_r2</th>\n",
              "      <th>attack_unsure_r2</th>\n",
              "      <th>defeater-undercutter_r2</th>\n",
              "      <th>defeater-undercutter_unsure_r2</th>\n",
              "      <th>fact-feeling_r2</th>\n",
              "      <th>fact-feeling_unsure_r2</th>\n",
              "      <th>negotiate-attack_r2</th>\n",
              "      <th>negotiate-attack_unsure_r2</th>\n",
              "      <th>nicenasty_r2</th>\n",
              "      <th>nicenasty_unsure_r2</th>\n",
              "      <th>personal-audience_r2</th>\n",
              "      <th>personal-audience_unsure_r2</th>\n",
              "      <th>questioning-asserting_r2</th>\n",
              "      <th>questioning-asserting_unsure_r2</th>\n",
              "      <th>sarcasm_r2</th>\n",
              "      <th>sarcasm_unsure_r2</th>\n",
              "      <th>discussion_id_y_r2</th>\n",
              "      <th>response_post_id_r2</th>\n",
              "      <th>quote_post_id_r2</th>\n",
              "      <th>term_r2</th>\n",
              "      <th>task1 num annot_r2</th>\n",
              "      <th>task2 num annot_r2</th>\n",
              "      <th>task2 num disagree_r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I remember looking at the classic evolutionary...</td>\n",
              "      <td>Why do you find it necessary to fit observatio...</td>\n",
              "      <td>Evolution has no goals, it is merely a beautif...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-2.833333</td>\n",
              "      <td>(731, 1)</td>\n",
              "      <td>6032</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-4.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>6032</td>\n",
              "      <td>149609</td>\n",
              "      <td>149552.0</td>\n",
              "      <td>None</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>(610, 2)</td>\n",
              "      <td>6032</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-3.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-4.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>6032</td>\n",
              "      <td>149673</td>\n",
              "      <td>149609.0</td>\n",
              "      <td>None</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the fun in that?</td>\n",
              "      <td>Seriously? Well, I come here hoping for someth...</td>\n",
              "      <td>nah, I was just poking fun because I can! Pers...</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-2.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.166667</td>\n",
              "      <td>(697, 2)</td>\n",
              "      <td>5205</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5205</td>\n",
              "      <td>122800</td>\n",
              "      <td>122780.0</td>\n",
              "      <td>None</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>(1267, 0)</td>\n",
              "      <td>5205</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>5205</td>\n",
              "      <td>123129</td>\n",
              "      <td>122800.0</td>\n",
              "      <td>None</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>First off, the scientific method goes:\\n \\n 1)...</td>\n",
              "      <td>You guys know me. Always happy to correct anyo...</td>\n",
              "      <td>Ah, thanks for the correction, although there ...</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>(9, 0)</td>\n",
              "      <td>9449</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-2.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-3.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>9449</td>\n",
              "      <td>247240</td>\n",
              "      <td>247225.0</td>\n",
              "      <td>you</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>(1393, 1)</td>\n",
              "      <td>9449</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>9449</td>\n",
              "      <td>247243</td>\n",
              "      <td>247240.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You can ignore the obvious question. This is w...</td>\n",
              "      <td>Actually what they are really doing is ignorin...</td>\n",
              "      <td>Really, then show me how I'm wrong - without d...</td>\n",
              "      <td>-3.500000</td>\n",
              "      <td>-3.166667</td>\n",
              "      <td>-3.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.833333</td>\n",
              "      <td>(1077, 1)</td>\n",
              "      <td>3467</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-4.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3467</td>\n",
              "      <td>73741</td>\n",
              "      <td>73738.0</td>\n",
              "      <td>actually</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>(622, 1)</td>\n",
              "      <td>3467</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>3467</td>\n",
              "      <td>73783</td>\n",
              "      <td>73741.0</td>\n",
              "      <td>really</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Its really sad what these gay predator priests...</td>\n",
              "      <td>Homosexuals are attracted to adults of the sam...</td>\n",
              "      <td>Homosexuals are attracted to people of the sam...</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>2.166667</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-2.666667</td>\n",
              "      <td>(611, 0)</td>\n",
              "      <td>4337</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>4337</td>\n",
              "      <td>112008</td>\n",
              "      <td>111931.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>(1350, 0)</td>\n",
              "      <td>4337</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4337</td>\n",
              "      <td>112012</td>\n",
              "      <td>112008.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1341</th>\n",
              "      <td>1. Did she do anything wrong?</td>\n",
              "      <td>Yes, she walked down the wrong alley, alone. W...</td>\n",
              "      <td>So it was wrong for her to walk down a public ...</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-3.333333</td>\n",
              "      <td>(27, 4)</td>\n",
              "      <td>13306</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>13306</td>\n",
              "      <td>370461</td>\n",
              "      <td>370385.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>(83, 5)</td>\n",
              "      <td>13306</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-3.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-2.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.666667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>13306</td>\n",
              "      <td>370646</td>\n",
              "      <td>370461.0</td>\n",
              "      <td>so</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1342</th>\n",
              "      <td>this is also the reason why atheism is more li...</td>\n",
              "      <td>It is curious how lately christians have been ...</td>\n",
              "      <td>Well, the type of atheism you are talking abou...</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>(1382, 6)</td>\n",
              "      <td>3982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-1.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-0.428571</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>3982</td>\n",
              "      <td>83610</td>\n",
              "      <td>83594.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>(974, 6)</td>\n",
              "      <td>3982</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3982</td>\n",
              "      <td>83636</td>\n",
              "      <td>83610.0</td>\n",
              "      <td>well</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1343</th>\n",
              "      <td>Assault weapons? first of all, what are assaul...</td>\n",
              "      <td>Thanks Patriot for the well researched respons...</td>\n",
              "      <td>The ban on assault weapons stands on such polt...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>(897, 4)</td>\n",
              "      <td>50</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>33286</td>\n",
              "      <td>173.0</td>\n",
              "      <td>None</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>(398, 4)</td>\n",
              "      <td>50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-2.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-1.200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>50</td>\n",
              "      <td>33347</td>\n",
              "      <td>33286.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1344</th>\n",
              "      <td>And without a gun you're defenseless, why can'...</td>\n",
              "      <td>Hardly any criminals go armed in England, and ...</td>\n",
              "      <td>All of the British papers keep going on about ...</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.800000</td>\n",
              "      <td>(1231, 1)</td>\n",
              "      <td>11999</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11999</td>\n",
              "      <td>333578</td>\n",
              "      <td>333574.0</td>\n",
              "      <td>None</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>(1393, 2)</td>\n",
              "      <td>11999</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-2.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>11999</td>\n",
              "      <td>333583</td>\n",
              "      <td>333578.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>What I don't understand is why YEC's want to L...</td>\n",
              "      <td>That's what faith does. It limits your options.</td>\n",
              "      <td>Here's a nice little Google def: A convinced b...</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>(1348, 1)</td>\n",
              "      <td>6032</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>6032</td>\n",
              "      <td>149609</td>\n",
              "      <td>149552.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>(402, 2)</td>\n",
              "      <td>6032</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6032</td>\n",
              "      <td>149673</td>\n",
              "      <td>149609.0</td>\n",
              "      <td>No terms in first 10</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1340 rows × 59 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b5f146c-405b-469f-a54e-65c14419f824')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b5f146c-405b-469f-a54e-65c14419f824 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b5f146c-405b-469f-a54e-65c14419f824');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9354561f-56e7-425a-b31e-3b8502b8355f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9354561f-56e7-425a-b31e-3b8502b8355f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9354561f-56e7-425a-b31e-3b8502b8355f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f717bab3-b302-4b5e-a97f-57233699ea65\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('triples')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f717bab3-b302-4b5e-a97f-57233699ea65 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('triples');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Self-merge where the 'response' matches another 'quote' in the DataFrame\n",
        "triples = pairs.merge(pairs,left_on='response',right_on='quote',how='inner',suffixes=('_r1','_r2'))\n",
        "\n",
        "# Rename and reorder columns\n",
        "triples = triples.rename(columns={'quote_r1':'quote', 'quote_r2':'response1', 'response_r2':'response2'})\n",
        "triples = triples.drop(columns=['response_r1'])\n",
        "front_columns = [\n",
        "                 'quote','response1','response2','attack_r1','fact-feeling_r1','nicenasty_r1','sarcasm_r1',\n",
        "                 'agreement_r2'\n",
        "                ]\n",
        "triples = triples.dropna(subset=front_columns)\n",
        "triples = triples[front_columns].join(triples.drop(columns=front_columns))\n",
        "\n",
        "# Display triples\n",
        "triples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ZdWJeaDUlR"
      },
      "source": [
        "Now we have 1,346 triples of quote-response1-response2, several text variables of response1 (e.g., \"Is the respondent using sarcasm?\") that may predict the agreement of response2. In other words: _Does a sarcastic comment lead to more agreement?_ Of course, as with almost all observational data, there are a number of confounders that make our identification difficult, but for now, let's explore how to run a simple regression in Python of agreement_r2 (dependent variable, commonly known as Y) on sarcasm_r1. Fortunately, we do have a strong case for identifying the direction of causality: Because response1 comes before response2, we can rule out the possibility that response2 affects response1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "qq_C4AliDUlR",
        "outputId": "4565a058-1ab9-4bf4-f50d-678657b71309"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:           agreement_r2   R-squared:                       0.000\n",
              "Model:                            OLS   Adj. R-squared:                 -0.001\n",
              "Method:                 Least Squares   F-statistic:                   0.03364\n",
              "Date:                Fri, 02 Feb 2024   Prob (F-statistic):              0.855\n",
              "Time:                        23:57:58   Log-Likelihood:                -2581.1\n",
              "No. Observations:                1340   AIC:                             5166.\n",
              "Df Residuals:                    1338   BIC:                             5177.\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const         -1.2805      0.058    -22.263      0.000      -1.393      -1.168\n",
              "sarcasm_r1    -0.0383      0.209     -0.183      0.855      -0.448       0.371\n",
              "==============================================================================\n",
              "Omnibus:                       86.710   Durbin-Watson:                   1.866\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              102.903\n",
              "Skew:                           0.642   Prob(JB):                     4.52e-23\n",
              "Kurtosis:                       3.443   Cond. No.                         4.73\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>      <td>agreement_r2</td>   <th>  R-squared:         </th> <td>   0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.03364</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 02 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.855</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:57:58</td>     <th>  Log-Likelihood:    </th> <td> -2581.1</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1340</td>      <th>  AIC:               </th> <td>   5166.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1338</td>      <th>  BIC:               </th> <td>   5177.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>      <td>   -1.2805</td> <td>    0.058</td> <td>  -22.263</td> <td> 0.000</td> <td>   -1.393</td> <td>   -1.168</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sarcasm_r1</th> <td>   -0.0383</td> <td>    0.209</td> <td>   -0.183</td> <td> 0.855</td> <td>   -0.448</td> <td>    0.371</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>86.710</td> <th>  Durbin-Watson:     </th> <td>   1.866</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 102.903</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.642</td> <th>  Prob(JB):          </th> <td>4.52e-23</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.443</td> <th>  Cond. No.          </th> <td>    4.73</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &  agreement\\_r2   & \\textbf{  R-squared:         } &     0.000   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &    -0.001   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &   0.03364   \\\\\n\\textbf{Date:}             & Fri, 02 Feb 2024 & \\textbf{  Prob (F-statistic):} &    0.855    \\\\\n\\textbf{Time:}             &     23:57:58     & \\textbf{  Log-Likelihood:    } &   -2581.1   \\\\\n\\textbf{No. Observations:} &        1340      & \\textbf{  AIC:               } &     5166.   \\\\\n\\textbf{Df Residuals:}     &        1338      & \\textbf{  BIC:               } &     5177.   \\\\\n\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}       &      -1.2805  &        0.058     &   -22.263  &         0.000        &       -1.393    &       -1.168     \\\\\n\\textbf{sarcasm\\_r1} &      -0.0383  &        0.209     &    -0.183  &         0.855        &       -0.448    &        0.371     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 86.710 & \\textbf{  Durbin-Watson:     } &    1.866  \\\\\n\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  102.903  \\\\\n\\textbf{Skew:}          &  0.642 & \\textbf{  Prob(JB):          } & 4.52e-23  \\\\\n\\textbf{Kurtosis:}      &  3.443 & \\textbf{  Cond. No.          } &     4.73  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# We build an Ordinary Least Squares (OLS) model of agreement_r2 on sarcasm_r1.\n",
        "# The function sm.add_constant() adds an intercept term to the regression (e.g., b in y = ax + b)\n",
        "y = triples['agreement_r2']\n",
        "X_cols = ['sarcasm_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "\n",
        "lm1 = sm.OLS(y,X).fit()\n",
        "lm1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llWnOZ03DUlS"
      },
      "source": [
        "The p-value for sarcasm_r1 is 0.855, which means that we fail to reject the null hypothesis that there is no effect of sarcasm on agreement. However, we have other variables that may be confounding the effect of pure \"attack\" or pure \"sarcasm.\" Let's try adding 3 other annotations to the regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "q6NFws5RDUlS",
        "outputId": "8f84387d-8a04-4c88-b598-59e213ecc53b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:           agreement_r2   R-squared:                       0.036\n",
              "Model:                            OLS   Adj. R-squared:                  0.034\n",
              "Method:                 Least Squares   F-statistic:                     12.60\n",
              "Date:                Fri, 02 Feb 2024   Prob (F-statistic):           4.54e-10\n",
              "Time:                        23:57:58   Log-Likelihood:                -2556.3\n",
              "No. Observations:                1340   AIC:                             5123.\n",
              "Df Residuals:                    1335   BIC:                             5149.\n",
              "Df Model:                           4                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===================================================================================\n",
              "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-----------------------------------------------------------------------------------\n",
              "const              -1.5276      0.075    -20.497      0.000      -1.674      -1.381\n",
              "attack_r1           0.1808      0.073      2.475      0.013       0.038       0.324\n",
              "fact-feeling_r1    -0.0248      0.033     -0.742      0.458      -0.090       0.041\n",
              "nicenasty_r1        0.0748      0.079      0.951      0.342      -0.079       0.229\n",
              "sarcasm_r1          0.6972      0.240      2.905      0.004       0.226       1.168\n",
              "==============================================================================\n",
              "Omnibus:                       86.269   Durbin-Watson:                   1.896\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              103.200\n",
              "Skew:                           0.629   Prob(JB):                     3.89e-23\n",
              "Kurtosis:                       3.517   Cond. No.                         12.8\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>      <td>agreement_r2</td>   <th>  R-squared:         </th> <td>   0.036</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.034</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.60</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 02 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>4.54e-10</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:57:58</td>     <th>  Log-Likelihood:    </th> <td> -2556.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1340</td>      <th>  AIC:               </th> <td>   5123.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1335</td>      <th>  BIC:               </th> <td>   5149.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>           <td>   -1.5276</td> <td>    0.075</td> <td>  -20.497</td> <td> 0.000</td> <td>   -1.674</td> <td>   -1.381</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>attack_r1</th>       <td>    0.1808</td> <td>    0.073</td> <td>    2.475</td> <td> 0.013</td> <td>    0.038</td> <td>    0.324</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>fact-feeling_r1</th> <td>   -0.0248</td> <td>    0.033</td> <td>   -0.742</td> <td> 0.458</td> <td>   -0.090</td> <td>    0.041</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>nicenasty_r1</th>    <td>    0.0748</td> <td>    0.079</td> <td>    0.951</td> <td> 0.342</td> <td>   -0.079</td> <td>    0.229</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sarcasm_r1</th>      <td>    0.6972</td> <td>    0.240</td> <td>    2.905</td> <td> 0.004</td> <td>    0.226</td> <td>    1.168</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>86.269</td> <th>  Durbin-Watson:     </th> <td>   1.896</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 103.200</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.629</td> <th>  Prob(JB):          </th> <td>3.89e-23</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.517</td> <th>  Cond. No.          </th> <td>    12.8</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &  agreement\\_r2   & \\textbf{  R-squared:         } &     0.036   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.034   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     12.60   \\\\\n\\textbf{Date:}             & Fri, 02 Feb 2024 & \\textbf{  Prob (F-statistic):} &  4.54e-10   \\\\\n\\textbf{Time:}             &     23:57:58     & \\textbf{  Log-Likelihood:    } &   -2556.3   \\\\\n\\textbf{No. Observations:} &        1340      & \\textbf{  AIC:               } &     5123.   \\\\\n\\textbf{Df Residuals:}     &        1335      & \\textbf{  BIC:               } &     5149.   \\\\\n\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}            &      -1.5276  &        0.075     &   -20.497  &         0.000        &       -1.674    &       -1.381     \\\\\n\\textbf{attack\\_r1}       &       0.1808  &        0.073     &     2.475  &         0.013        &        0.038    &        0.324     \\\\\n\\textbf{fact-feeling\\_r1} &      -0.0248  &        0.033     &    -0.742  &         0.458        &       -0.090    &        0.041     \\\\\n\\textbf{nicenasty\\_r1}    &       0.0748  &        0.079     &     0.951  &         0.342        &       -0.079    &        0.229     \\\\\n\\textbf{sarcasm\\_r1}      &       0.6972  &        0.240     &     2.905  &         0.004        &        0.226    &        1.168     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 86.269 & \\textbf{  Durbin-Watson:     } &    1.896  \\\\\n\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  103.200  \\\\\n\\textbf{Skew:}          &  0.629 & \\textbf{  Prob(JB):          } & 3.89e-23  \\\\\n\\textbf{Kurtosis:}      &  3.517 & \\textbf{  Cond. No.          } &     12.8  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "y = triples['agreement_r2']\n",
        "X_cols = ['attack_r1','fact-feeling_r1','nicenasty_r1','sarcasm_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "\n",
        "lm2 = sm.OLS(y,X).fit()\n",
        "lm2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sroj_p4eDUlS"
      },
      "source": [
        "The condition number (bottom-right of the output above) is 12.8, indicating high correlations between our predictors or collinearity. This is one of many issues to look out for when running regressions. Let's take a look at the correlations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "3jyYqtNHDUlS",
        "outputId": "4aedb1f6-44d6-4bd8-d0a5-56b86a59e560"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "corr_matrix = np.corrcoef(triples[X_cols].T)\n",
        "smg.plot_corr(corr_matrix, xnames=X_cols)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kchnw-nJDUlT"
      },
      "source": [
        "That's very high correlation between attack_r1 and nicenasty_r1 (recall that nasty is +5...this should be no surprise)! We found a significant effect of attack_r1, but not of nicenasty_r1. If we remove attack_r1 from the model, do you think nicenasty_r1 will be significant?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "vHsLKsGCDUlT",
        "outputId": "0b4ffc17-5850-415b-e248-bd6b14fb2496"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:           agreement_r2   R-squared:                       0.032\n",
              "Model:                            OLS   Adj. R-squared:                  0.030\n",
              "Method:                 Least Squares   F-statistic:                     14.71\n",
              "Date:                Fri, 02 Feb 2024   Prob (F-statistic):           2.00e-09\n",
              "Time:                        23:58:00   Log-Likelihood:                -2559.3\n",
              "No. Observations:                1340   AIC:                             5127.\n",
              "Df Residuals:                    1336   BIC:                             5147.\n",
              "Df Model:                           3                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===================================================================================\n",
              "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-----------------------------------------------------------------------------------\n",
              "const              -1.5744      0.072    -21.798      0.000      -1.716      -1.433\n",
              "fact-feeling_r1    -0.0183      0.033     -0.548      0.584      -0.084       0.047\n",
              "nicenasty_r1        0.2454      0.038      6.488      0.000       0.171       0.320\n",
              "sarcasm_r1          0.7113      0.240      2.959      0.003       0.240       1.183\n",
              "==============================================================================\n",
              "Omnibus:                       85.105   Durbin-Watson:                   1.893\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.648\n",
              "Skew:                           0.623   Prob(JB):                     8.46e-23\n",
              "Kurtosis:                       3.518   Cond. No.                         10.3\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>      <td>agreement_r2</td>   <th>  R-squared:         </th> <td>   0.032</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.030</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.71</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 02 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>2.00e-09</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:58:00</td>     <th>  Log-Likelihood:    </th> <td> -2559.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1340</td>      <th>  AIC:               </th> <td>   5127.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1336</td>      <th>  BIC:               </th> <td>   5147.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>           <td>   -1.5744</td> <td>    0.072</td> <td>  -21.798</td> <td> 0.000</td> <td>   -1.716</td> <td>   -1.433</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>fact-feeling_r1</th> <td>   -0.0183</td> <td>    0.033</td> <td>   -0.548</td> <td> 0.584</td> <td>   -0.084</td> <td>    0.047</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>nicenasty_r1</th>    <td>    0.2454</td> <td>    0.038</td> <td>    6.488</td> <td> 0.000</td> <td>    0.171</td> <td>    0.320</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sarcasm_r1</th>      <td>    0.7113</td> <td>    0.240</td> <td>    2.959</td> <td> 0.003</td> <td>    0.240</td> <td>    1.183</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>85.105</td> <th>  Durbin-Watson:     </th> <td>   1.893</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 101.648</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.623</td> <th>  Prob(JB):          </th> <td>8.46e-23</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.518</td> <th>  Cond. No.          </th> <td>    10.3</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &  agreement\\_r2   & \\textbf{  R-squared:         } &     0.032   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.030   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     14.71   \\\\\n\\textbf{Date:}             & Fri, 02 Feb 2024 & \\textbf{  Prob (F-statistic):} &  2.00e-09   \\\\\n\\textbf{Time:}             &     23:58:00     & \\textbf{  Log-Likelihood:    } &   -2559.3   \\\\\n\\textbf{No. Observations:} &        1340      & \\textbf{  AIC:               } &     5127.   \\\\\n\\textbf{Df Residuals:}     &        1336      & \\textbf{  BIC:               } &     5147.   \\\\\n\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}            &      -1.5744  &        0.072     &   -21.798  &         0.000        &       -1.716    &       -1.433     \\\\\n\\textbf{fact-feeling\\_r1} &      -0.0183  &        0.033     &    -0.548  &         0.584        &       -0.084    &        0.047     \\\\\n\\textbf{nicenasty\\_r1}    &       0.2454  &        0.038     &     6.488  &         0.000        &        0.171    &        0.320     \\\\\n\\textbf{sarcasm\\_r1}      &       0.7113  &        0.240     &     2.959  &         0.003        &        0.240    &        1.183     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 85.105 & \\textbf{  Durbin-Watson:     } &    1.893  \\\\\n\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  101.648  \\\\\n\\textbf{Skew:}          &  0.623 & \\textbf{  Prob(JB):          } & 8.46e-23  \\\\\n\\textbf{Kurtosis:}      &  3.518 & \\textbf{  Cond. No.          } &     10.3  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y = triples['agreement_r2']\n",
        "X_cols = ['fact-feeling_r1','nicenasty_r1','sarcasm_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "\n",
        "lm2 = sm.OLS(y,X).fit()\n",
        "lm2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlp9iNlHDUlT"
      },
      "source": [
        "Yes, it is! And the t-value is even larger (i.e., stronger evidence of an effect). With this new regression model, we see a significant effect from attack_r1/nicenasty_r1 and sarcasm_r1, indicating both of these dimensions affect whether the response2 agrees with response1. Note that the coefficients are both positive: For attack_r1/nicenasty_r1, this means that a more \"nasty\" comment led to more disagreement, and for sarcasm_r1, this means that a more sarcasistic comment led to more disagreement.\n",
        "\n",
        "For good measure, we can add other variables ourselves, such as sentiment and the character length of the comment. The length may be particularly important based on how it affects the annotations of Mechanical Turk workers. For example, as we were skimming through the data, it seemed like shorter comments were being rated as more nasty. For sentiment, let's use the convenient BERT pipeline we used last week and which we will detail and theorize in weeks to come."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T-SRfJSDUlU"
      },
      "outputs": [],
      "source": [
        "triples['length_r1'] = triples['response1'].apply(lambda x: len(x))\n",
        "triples['length_r2'] = triples['response2'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "bcb9f456382b45e09f2037ed428550ac",
            "e5a9927927e846be82255c68dc291075",
            "e90eeb42968d4cfd834c08827c7fe95e",
            "02bca7b5201748ba84aa79e097c4b833",
            "8abbd4ab6de0475c8fe7154418525b15",
            "f3aedae259134ba38e2576294e056c1b",
            "ad708236ea944065b2a6aa3466b9bba9",
            "30d09611b8aa4b05a367f1a2a8f5389c",
            "17ba6c21c256439cbd641a84b65ebede",
            "955ff6ddccec44bf8641198de96f4e46",
            "831192cbf963447cba781bfb39d2ec3e",
            "eb8ac8bc48414fe980096f00114bfdb6",
            "735cbc4d10c14c0a9fcad64a69447382",
            "cd45edc660014cce843c82e6b582b5d1",
            "1c57b3448b144d23b924bfef52c52206",
            "1f80b2a3d4414535826b5025dfb09feb",
            "7400e647f8614d30ad788e7f741d77f5",
            "ddb6a68cff124d9888199b762166d334",
            "f54b79ec1f5942cf8842d7d8c410da73",
            "a7fc4079bc2b49e9bae276d4025219ac",
            "84faba4eef8f435db0e54aadf93fa517",
            "57b2c18f64d04b4fa389147184aa8acb",
            "4ab733528a5247f792e2d8422c882cba",
            "13a47573af5a4677b6e104df6059b36f",
            "29afdd1a279447d2b5ee0816783062ef",
            "cf0e451463d94e359282f6f7335e77e7",
            "d81bc038fe9c41c7a59a623dc4a80638",
            "a99cec64baf544199271eb3cb073c478",
            "c95cb5ce096246018a5510b2c97532bc",
            "39cfafcfc6764ba89c44741343194699",
            "4b3a83d2ba8447228b8f057bc7abb580",
            "057f71eb82084ee98c590b5bde07edc2",
            "b436f5061eb444d7b47d01d7a1dfab96",
            "787ce6cf82374df5b970f954273d027b",
            "dbfc25c5c28941428056a04448354e2f",
            "b6a715026f7c4b31aeae2922f8f7b7cd",
            "41550aa3ecf349adb19c4cb421e12b2c",
            "2131109f98d34e85ba4164e70466954c",
            "3877b488ea6b4e38a6497a959a4710b8",
            "08d38d813f5d4f01ad87b0d72a27183e",
            "851d981f6ee34fd6859b5fffbec199b1",
            "63551829a748456fbe759b84a8fc1ac8",
            "ba8474d942094866ac27fee1d3321d02",
            "61a9de8ae4cd4adda85a063538f34d6d"
          ]
        },
        "id": "SB6FU0EoDUlU",
        "outputId": "dff91e06-6fbe-4920-a967-c138fd79bb13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcb9f456382b45e09f2037ed428550ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb8ac8bc48414fe980096f00114bfdb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ab733528a5247f792e2d8422c882cba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "787ce6cf82374df5b970f954273d027b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: NEGATIVE, with score: 0.9991\n"
          ]
        }
      ],
      "source": [
        "sentiment = pipeline(\"sentiment-analysis\")\n",
        "result = sentiment(\"I hate you\")[0]\n",
        "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhXGdwJyDUlU"
      },
      "source": [
        "This version of BERT is built only for texts of up to 512 tokens, so for comments longer than that, we truncate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7SBbeGGDUlV",
        "outputId": "c9a345f6-5af3-4a1e-a717-c4342eb24f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5min 16s, sys: 555 ms, total: 5min 16s\n",
            "Wall time: 5min 29s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "triples['sentiment_r1'] = triples['response1'].apply(lambda x: sentiment(x[:512])[0]['score'])\n",
        "triples['sentiment_r2'] = triples['response2'].apply(lambda x: sentiment(x[:512])[0]['score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "D7SMSIDhDUlV",
        "outputId": "1dcc81b5-8028-4a85-9dbd-3784f8614590"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:           agreement_r2   R-squared:                       0.033\n",
              "Model:                            OLS   Adj. R-squared:                  0.029\n",
              "Method:                 Least Squares   F-statistic:                     9.032\n",
              "Date:                Sat, 03 Feb 2024   Prob (F-statistic):           1.87e-08\n",
              "Time:                        00:03:37   Log-Likelihood:                -2558.8\n",
              "No. Observations:                1340   AIC:                             5130.\n",
              "Df Residuals:                    1334   BIC:                             5161.\n",
              "Df Model:                           5                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===================================================================================\n",
              "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-----------------------------------------------------------------------------------\n",
              "const              -1.3211      0.522     -2.531      0.011      -2.345      -0.297\n",
              "fact-feeling_r1    -0.0126      0.034     -0.370      0.711      -0.079       0.054\n",
              "nicenasty_r1        0.2433      0.038      6.419      0.000       0.169       0.318\n",
              "sarcasm_r1          0.6985      0.241      2.901      0.004       0.226       1.171\n",
              "length_r1          -0.0001      0.000     -0.935      0.350      -0.000       0.000\n",
              "sentiment_r1       -0.2225      0.534     -0.417      0.677      -1.270       0.825\n",
              "==============================================================================\n",
              "Omnibus:                       85.913   Durbin-Watson:                   1.890\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              102.861\n",
              "Skew:                           0.626   Prob(JB):                     4.61e-23\n",
              "Kurtosis:                       3.526   Cond. No.                     7.04e+03\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 7.04e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>      <td>agreement_r2</td>   <th>  R-squared:         </th> <td>   0.033</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.029</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.032</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 03 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>1.87e-08</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>00:03:37</td>     <th>  Log-Likelihood:    </th> <td> -2558.8</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1340</td>      <th>  AIC:               </th> <td>   5130.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1334</td>      <th>  BIC:               </th> <td>   5161.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>           <td>   -1.3211</td> <td>    0.522</td> <td>   -2.531</td> <td> 0.011</td> <td>   -2.345</td> <td>   -0.297</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>fact-feeling_r1</th> <td>   -0.0126</td> <td>    0.034</td> <td>   -0.370</td> <td> 0.711</td> <td>   -0.079</td> <td>    0.054</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>nicenasty_r1</th>    <td>    0.2433</td> <td>    0.038</td> <td>    6.419</td> <td> 0.000</td> <td>    0.169</td> <td>    0.318</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sarcasm_r1</th>      <td>    0.6985</td> <td>    0.241</td> <td>    2.901</td> <td> 0.004</td> <td>    0.226</td> <td>    1.171</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>length_r1</th>       <td>   -0.0001</td> <td>    0.000</td> <td>   -0.935</td> <td> 0.350</td> <td>   -0.000</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sentiment_r1</th>    <td>   -0.2225</td> <td>    0.534</td> <td>   -0.417</td> <td> 0.677</td> <td>   -1.270</td> <td>    0.825</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>85.913</td> <th>  Durbin-Watson:     </th> <td>   1.890</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 102.861</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.626</td> <th>  Prob(JB):          </th> <td>4.61e-23</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.526</td> <th>  Cond. No.          </th> <td>7.04e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.04e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &  agreement\\_r2   & \\textbf{  R-squared:         } &     0.033   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.029   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     9.032   \\\\\n\\textbf{Date:}             & Sat, 03 Feb 2024 & \\textbf{  Prob (F-statistic):} &  1.87e-08   \\\\\n\\textbf{Time:}             &     00:03:37     & \\textbf{  Log-Likelihood:    } &   -2558.8   \\\\\n\\textbf{No. Observations:} &        1340      & \\textbf{  AIC:               } &     5130.   \\\\\n\\textbf{Df Residuals:}     &        1334      & \\textbf{  BIC:               } &     5161.   \\\\\n\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}            &      -1.3211  &        0.522     &    -2.531  &         0.011        &       -2.345    &       -0.297     \\\\\n\\textbf{fact-feeling\\_r1} &      -0.0126  &        0.034     &    -0.370  &         0.711        &       -0.079    &        0.054     \\\\\n\\textbf{nicenasty\\_r1}    &       0.2433  &        0.038     &     6.419  &         0.000        &        0.169    &        0.318     \\\\\n\\textbf{sarcasm\\_r1}      &       0.6985  &        0.241     &     2.901  &         0.004        &        0.226    &        1.171     \\\\\n\\textbf{length\\_r1}       &      -0.0001  &        0.000     &    -0.935  &         0.350        &       -0.000    &        0.000     \\\\\n\\textbf{sentiment\\_r1}    &      -0.2225  &        0.534     &    -0.417  &         0.677        &       -1.270    &        0.825     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 85.913 & \\textbf{  Durbin-Watson:     } &    1.890  \\\\\n\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  102.861  \\\\\n\\textbf{Skew:}          &  0.626 & \\textbf{  Prob(JB):          } & 4.61e-23  \\\\\n\\textbf{Kurtosis:}      &  3.526 & \\textbf{  Cond. No.          } & 7.04e+03  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The condition number is large, 7.04e+03. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems."
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y = triples['agreement_r2']\n",
        "X_cols = ['fact-feeling_r1','nicenasty_r1','sarcasm_r1','length_r1','sentiment_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "\n",
        "lm2 = sm.OLS(y,X).fit()\n",
        "lm2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "a9cfB5pjDUlV",
        "outputId": "6e240768-5065-4e74-90dd-8f14c059c9c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "corr_matrix = np.corrcoef(triples[X_cols].T)\n",
        "smg.plot_corr(corr_matrix, xnames=X_cols)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzkZgmhDUlV"
      },
      "source": [
        "The condition number is reasonably high, but our correlatons do not seem too strong. Overall, our finding of significant effects for attack_r1/nasty_r1 and sarcasm_r1 persists with these new controls! This sort of robustness or sensitivity analysis is important for making sure your finding is compelling to yourself and to your audience. Consider doing other robustness checks, such as standardizing these variables before running the regression or adding [robust standard errors](https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors). (To be clear, the analysis above would likely not be sufficient as proof of a causal effect for a peer-reviewed journal; you would likely need a more conditional approach using matching, instruments or differences in differences.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdJ8l9wcDUlW"
      },
      "source": [
        "## <font color=\"red\">*Exercise 2*</font>\n",
        "\n",
        "<font color=\"red\">Propose a simple causal model in your data, or a different causal model in the annotated Internet Arguments Corpus (e.g., a different treatment, a different outcome), and test it using a linear or logistic regression model. If you are using social media data for your final project, we encourage you to classify or annotate a sample of that data (either compuationally or with human annotators) and examine the effect of texts on replies to that text (e.g., Reddit posts on Reddit comments, Tweets on Twitter replies, YouTube video transcripts on YouTube comments or ratings). You do not need to make a graph of the causal model, but please make it clear (e.g., \"X affects Y, and C affects both X and Y.\").\n",
        "    \n",
        "<font color=\"red\">Also consider using the [ConvoKit datasets](https://convokit.cornell.edu/documentation/datasets.html)! Anytime there is conversation, there is an opportunity to explore the effects of early parts of the conversation on later parts. We will explore this further in Week 8 on Text Generation and Conversation.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Propose a more robust identification strategy using either matching, difference in difference, regression discontinuity, or an instrumental variable. Each of these methods usually gives you a more precise identification of the causal effect than a unconditional regression. Scott Cunningham's [Causal Inference: The Mixtape](https://mixtape.scunning.com/) is a free textbook on these topics, and all have good YouTube video explanations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import jieba\n",
        "from collections import Counter\n",
        "\n",
        "# 载入数据\n",
        "df = pd.read_csv('/content/predicted_shanghaidata.csv').head(500)\n",
        "\n",
        "# 中文分词\n",
        "df['分词'] = df['标题/微博内容'].apply(lambda x: list(jieba.cut(x)))\n",
        "\n",
        "# 计算每个情感类别的最常出现的词语\n",
        "sentiments = df['预测情感'].unique()\n",
        "top_words_per_sentiment = {}\n",
        "\n",
        "for sentiment in sentiments:\n",
        "    # 获取该情感下的所有微博分词\n",
        "    all_words = sum(df[df['预测情感'] == sentiment]['分词'], [])\n",
        "    # 计数最常见的词语\n",
        "    word_counts = Counter(all_words)\n",
        "    # 获取最常见的10个词语\n",
        "    top_words_per_sentiment[sentiment] = word_counts.most_common(10)\n",
        "\n",
        "# 输出结果\n",
        "for sentiment, words in top_words_per_sentiment.items():\n",
        "    print(f\"\\n{sentiment}类别下的最常见词语：\")\n",
        "    for word, count in words:\n",
        "        print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLD_HDXMFNY7",
        "outputId": "460f68ea-069a-4a56-f83e-1e4a48c60b4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-bf4915598992>:6: DtypeWarning: Columns (0,14,17,19,20,21,22,23,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/predicted_shanghaidata.csv').head(500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "信任类别下的最常见词语：\n",
            "，: 985\n",
            "的: 501\n",
            "。: 338\n",
            "、: 211\n",
            "疫情: 165\n",
            "上海: 112\n",
            "和: 105\n",
            "在: 103\n",
            "”: 100\n",
            "“: 99\n",
            "\n",
            "期待类别下的最常见词语：\n",
            "，: 969\n",
            "的: 462\n",
            "。: 352\n",
            "、: 185\n",
            " : 171\n",
            "上海: 119\n",
            "疫情: 98\n",
            "月: 94\n",
            "了: 91\n",
            "“: 84\n",
            "\n",
            "厌恶类别下的最常见词语：\n",
            "，: 1598\n",
            "的: 921\n",
            "。: 531\n",
            " : 428\n",
            "上海: 364\n",
            "了: 307\n",
            "疫情: 267\n",
            "​: 231\n",
            "是: 228\n",
            "#: 193\n",
            "\n",
            "中性类别下的最常见词语：\n",
            "，: 1247\n",
            "的: 457\n",
            "。: 457\n",
            "、: 419\n",
            " : 266\n",
            "）: 191\n",
            "（: 188\n",
            "例: 184\n",
            "疫情: 177\n",
            "上海: 174\n",
            "\n",
            "悲伤类别下的最常见词语：\n",
            "，: 728\n",
            "的: 377\n",
            "了: 276\n",
            "。: 214\n",
            " : 211\n",
            "我: 157\n",
            "上海: 125\n",
            "​: 111\n",
            "是: 107\n",
            "[: 105\n",
            "\n",
            "其他类别下的最常见词语：\n",
            "，: 262\n",
            "的: 147\n",
            " : 120\n",
            "。: 106\n",
            "我: 97\n",
            "了: 92\n",
            "​: 58\n",
            "上海: 50\n",
            "说: 49\n",
            "是: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHeHuT-_eyez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools.tools import add_constant\n",
        "import numpy as np  # 确保导入了numpy\n",
        "\n",
        "# 加载数据\n",
        "df = pd.read_csv('/content/predicted_shanghaidata.csv').head(100)\n",
        "\n",
        "# 创建文本长度特征\n",
        "df['length'] = df['标题/微博内容'].apply(len)\n",
        "\n",
        "# 初始化情感分析模型\n",
        "sentiment_model = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# 确保文本长度不超过512字符\n",
        "def preprocess_text(text, max_length=500):\n",
        "    return text[:max_length]\n",
        "\n",
        "# 应用情感分析并获取情感得分\n",
        "def get_sentiment_score(text):\n",
        "    try:\n",
        "        processed_text = preprocess_text(text)\n",
        "        result = sentiment_model(processed_text)[0]\n",
        "        return result['score']\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        return np.nan  # 发生错误时返回NaN\n",
        "\n",
        "df['sentiment_score'] = df['标题/微博内容'].apply(get_sentiment_score)\n",
        "\n",
        "# 处理可能的缺失值或无穷大值\n",
        "df.dropna(inplace=True)  # 移除含有NaN值的行\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)  # 将inf替换为NaN\n",
        "df.dropna(inplace=True)  # 再次移除出现NaN的行\n",
        "\n",
        "# 准备模型数据\n",
        "X = df[['length', 'sentiment_score']]\n",
        "X = add_constant(X)  # 添加常数项\n",
        "y = df['预测情感'].astype(int)  # 确保响应变量是整数类型\n",
        "\n",
        "# 检查X和y不为空\n",
        "if not X.empty and not y.empty and not X.isnull().values.any() and not y.isnull().values.any():\n",
        "    # 拟合多项逻辑回归模型\n",
        "    model = sm.MNLogit(y, X).fit()\n",
        "    print(model.summary())\n",
        "else:\n",
        "    print(\"X or y contains NaN, inf, -inf, or is empty.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01ZEexoQR3s2",
        "outputId": "998c682f-0d0a-44a1-e148-78a934b67f8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-370ef12c614c>:8: DtypeWarning: Columns (0,14,17,19,20,21,22,23,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/predicted_shanghaidata.csv').head(100)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X or y contains NaN, inf, -inf, or is empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/predicted_shanghaidata.csv').head(200)\n",
        "# 情绪到数字的映射\n",
        "emotion_to_num = {\n",
        "    '厌恶': 0,\n",
        "    '悲伤': 1,\n",
        "    '信任': 2,\n",
        "    '期待': 3,\n",
        "    '其他': 4,  # '其他' 包括 '愤怒', '喜悦', '恐惧', '惊讶'\n",
        "    '中性': 5\n",
        "}\n",
        "data['length'] =data['标题/微博内容'].apply(len)\n",
        "# 将特定情感分类为\"其他\"并转换为数字\n",
        "emotions_to_combine = ['愤怒', '喜悦', '恐惧', '惊讶']\n",
        "data['情预测情感'] = data['预测情感'].apply(lambda x: '其他' if x in emotions_to_combine else x)\n",
        "data['预测情感'] = data['预测情感'].map(emotion_to_num)\n",
        "\n",
        "y = data['预测情感']\n",
        "X_cols = ['length']\n",
        "X = sm.add_constant(data[X_cols])\n",
        "\n",
        "lm1 = sm.OLS(y,X).fit()\n",
        "lm1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "saJRtb-he0B2",
        "outputId": "d16d11f2-a530-4af2-8ff2-4088914adc69"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-59820bd48ff2>:1: DtypeWarning: Columns (0,14,17,19,20,21,22,23,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('/content/predicted_shanghaidata.csv').head(200)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                   预测情感   R-squared:                       0.043\n",
              "Model:                            OLS   Adj. R-squared:                  0.039\n",
              "Method:                 Least Squares   F-statistic:                     8.968\n",
              "Date:                Wed, 21 Feb 2024   Prob (F-statistic):            0.00310\n",
              "Time:                        21:07:54   Log-Likelihood:                -410.19\n",
              "No. Observations:                 200   AIC:                             824.4\n",
              "Df Residuals:                     198   BIC:                             831.0\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          1.7210      0.184      9.349      0.000       1.358       2.084\n",
              "length         0.0013      0.000      2.995      0.003       0.000       0.002\n",
              "==============================================================================\n",
              "Omnibus:                      141.531   Durbin-Watson:                   1.696\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.331\n",
              "Skew:                           0.346   Prob(JB):                     0.000172\n",
              "Kurtosis:                       1.734   Cond. No.                         601.\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>预测情感</td>       <th>  R-squared:         </th> <td>   0.043</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.039</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.968</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 21 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>0.00310</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>21:07:54</td>     <th>  Log-Likelihood:    </th> <td> -410.19</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   824.4</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   198</td>      <th>  BIC:               </th> <td>   831.0</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>  <td>    1.7210</td> <td>    0.184</td> <td>    9.349</td> <td> 0.000</td> <td>    1.358</td> <td>    2.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>length</th> <td>    0.0013</td> <td>    0.000</td> <td>    2.995</td> <td> 0.003</td> <td>    0.000</td> <td>    0.002</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>141.531</td> <th>  Durbin-Watson:     </th> <td>   1.696</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  17.331</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.346</td>  <th>  Prob(JB):          </th> <td>0.000172</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.734</td>  <th>  Cond. No.          </th> <td>    601.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &       预测情感       & \\textbf{  R-squared:         } &     0.043   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.039   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     8.968   \\\\\n\\textbf{Date:}             & Wed, 21 Feb 2024 & \\textbf{  Prob (F-statistic):} &  0.00310    \\\\\n\\textbf{Time:}             &     21:07:54     & \\textbf{  Log-Likelihood:    } &   -410.19   \\\\\n\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &     824.4   \\\\\n\\textbf{Df Residuals:}     &         198      & \\textbf{  BIC:               } &     831.0   \\\\\n\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}  &       1.7210  &        0.184     &     9.349  &         0.000        &        1.358    &        2.084     \\\\\n\\textbf{length} &       0.0013  &        0.000     &     2.995  &         0.003        &        0.000    &        0.002     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 141.531 & \\textbf{  Durbin-Watson:     } &    1.696  \\\\\n\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   17.331  \\\\\n\\textbf{Skew:}          &   0.346 & \\textbf{  Prob(JB):          } & 0.000172  \\\\\n\\textbf{Kurtosis:}      &   1.734 & \\textbf{  Cond. No.          } &     601.  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = np.corrcoef(data[X_cols].T)\n",
        "smg.plot_corr(corr_matrix, xnames=X_cols)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "BNHsRm45h5Ck",
        "outputId": "d5286931-52ee-4309-b4d9-767a9ea577f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/graphics/correlation.py:112: UserWarning: Glyph 31881 (\\N{CJK UNIFIED IDEOGRAPH-7C89}) missing from current font.\n",
            "  fig.tight_layout()\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/graphics/correlation.py:112: UserWarning: Glyph 19997 (\\N{CJK UNIFIED IDEOGRAPH-4E1D}) missing from current font.\n",
            "  fig.tight_layout()\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/graphics/correlation.py:112: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
            "  fig.tight_layout()\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/graphics/correlation.py:112: UserWarning: Glyph 35780 (\\N{CJK UNIFIED IDEOGRAPH-8BC4}) missing from current font.\n",
            "  fig.tight_layout()\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/graphics/correlation.py:112: UserWarning: Glyph 35770 (\\N{CJK UNIFIED IDEOGRAPH-8BBA}) missing from current font.\n",
            "  fig.tight_layout()\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 35780 (\\N{CJK UNIFIED IDEOGRAPH-8BC4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 35770 (\\N{CJK UNIFIED IDEOGRAPH-8BBA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 31881 (\\N{CJK UNIFIED IDEOGRAPH-7C89}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 19997 (\\N{CJK UNIFIED IDEOGRAPH-4E1D}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm2 = sm.OLS(y,X).fit()\n",
        "lm2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "XbQHOMUwfyfM",
        "outputId": "849eef35-235b-4ccd-dee6-8f4baa1f9e43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                   预测情感   R-squared:                       0.043\n",
              "Model:                            OLS   Adj. R-squared:                  0.039\n",
              "Method:                 Least Squares   F-statistic:                     8.968\n",
              "Date:                Wed, 21 Feb 2024   Prob (F-statistic):            0.00310\n",
              "Time:                        21:08:50   Log-Likelihood:                -410.19\n",
              "No. Observations:                 200   AIC:                             824.4\n",
              "Df Residuals:                     198   BIC:                             831.0\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          1.7210      0.184      9.349      0.000       1.358       2.084\n",
              "length         0.0013      0.000      2.995      0.003       0.000       0.002\n",
              "==============================================================================\n",
              "Omnibus:                      141.531   Durbin-Watson:                   1.696\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.331\n",
              "Skew:                           0.346   Prob(JB):                     0.000172\n",
              "Kurtosis:                       1.734   Cond. No.                         601.\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>预测情感</td>       <th>  R-squared:         </th> <td>   0.043</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.039</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.968</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 21 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>0.00310</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>21:08:50</td>     <th>  Log-Likelihood:    </th> <td> -410.19</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   824.4</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   198</td>      <th>  BIC:               </th> <td>   831.0</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>  <td>    1.7210</td> <td>    0.184</td> <td>    9.349</td> <td> 0.000</td> <td>    1.358</td> <td>    2.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>length</th> <td>    0.0013</td> <td>    0.000</td> <td>    2.995</td> <td> 0.003</td> <td>    0.000</td> <td>    0.002</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>141.531</td> <th>  Durbin-Watson:     </th> <td>   1.696</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  17.331</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.346</td>  <th>  Prob(JB):          </th> <td>0.000172</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.734</td>  <th>  Cond. No.          </th> <td>    601.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &       预测情感       & \\textbf{  R-squared:         } &     0.043   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.039   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     8.968   \\\\\n\\textbf{Date:}             & Wed, 21 Feb 2024 & \\textbf{  Prob (F-statistic):} &  0.00310    \\\\\n\\textbf{Time:}             &     21:08:50     & \\textbf{  Log-Likelihood:    } &   -410.19   \\\\\n\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &     824.4   \\\\\n\\textbf{Df Residuals:}     &         198      & \\textbf{  BIC:               } &     831.0   \\\\\n\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}  &       1.7210  &        0.184     &     9.349  &         0.000        &        1.358    &        2.084     \\\\\n\\textbf{length} &       0.0013  &        0.000     &     2.995  &         0.003        &        0.000    &        0.002     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 141.531 & \\textbf{  Durbin-Watson:     } &    1.696  \\\\\n\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   17.331  \\\\\n\\textbf{Skew:}          &   0.346 & \\textbf{  Prob(JB):          } & 0.000172  \\\\\n\\textbf{Kurtosis:}      &   1.734 & \\textbf{  Cond. No.          } &     601.  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# 假设你已经加载了数据到data DataFrame\n",
        "# data = pd.read_csv('your_file.csv')  # 加载数据\n",
        "\n",
        "# 确保数值列是正确的数据类型\n",
        "data['预测情感'] = pd.to_numeric(data['预测情感'], errors='coerce')\n",
        "data['length'] = pd.to_numeric(data['length'], errors='coerce')\n",
        "data['粉丝数'] = pd.to_numeric(data['粉丝数'], errors='coerce')\n",
        "data['评论数'] = pd.to_numeric(data['评论数'], errors='coerce')\n",
        "\n",
        "# 处理缺失值，这里简单地丢弃含有NaN的行\n",
        "data.dropna(subset=['预测情感', 'length', '粉丝数', '评论数'], inplace=True)\n",
        "\n",
        "# 为回归准备数据\n",
        "y = data['预测情感']\n",
        "X_cols = ['length', '粉丝数', '评论数']\n",
        "X = sm.add_constant(data[X_cols])\n",
        "\n",
        "# 执行OLS回归\n",
        "lm2 = sm.OLS(y, X).fit()\n",
        "\n",
        "# 打印回归摘要\n",
        "print(lm2.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vawWAmXAf_27",
        "outputId": "9925262b-b793-4dbb-ee1e-13e43b316e96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                   预测情感   R-squared:                       0.082\n",
            "Model:                            OLS   Adj. R-squared:                  0.068\n",
            "Method:                 Least Squares   F-statistic:                     5.861\n",
            "Date:                Wed, 21 Feb 2024   Prob (F-statistic):           0.000747\n",
            "Time:                        21:11:19   Log-Likelihood:                -406.03\n",
            "No. Observations:                 200   AIC:                             820.1\n",
            "Df Residuals:                     196   BIC:                             833.3\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          1.6746      0.183      9.144      0.000       1.313       2.036\n",
            "length         0.0012      0.000      2.871      0.005       0.000       0.002\n",
            "粉丝数         6.208e-07    2.2e-07      2.820      0.005    1.87e-07    1.06e-06\n",
            "评论数           -0.0110      0.017     -0.653      0.514      -0.044       0.022\n",
            "==============================================================================\n",
            "Omnibus:                       98.035   Durbin-Watson:                   1.771\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               16.958\n",
            "Skew:                           0.385   Prob(JB):                     0.000208\n",
            "Kurtosis:                       1.799   Cond. No.                     8.50e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 8.5e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpYhJA4mDUlW"
      },
      "source": [
        "## Splitting training and test text\n",
        "Above, we used a number of external measures of text, meaning that the measures were developed without any influence from this dataset. For annotations, it was Mechanical Turk workers measuring the text. For length, that is a mathematical count of characters. For sentiment, it was from a BERT model not trained on the Internet Arguments Corpus.\n",
        "\n",
        "This is not always the case. Consider if we want to make a measure of the text based on topic modeling. We build an LDA topic model of these comments, then we select an appealingly relevant topic and measure what number of words from Topic 1 each comment uses. Can we put that measure in the regression? We could, but it would lead to a biased estimate of the true effect size because our measure is no longer external or exogenous. The measure and model are double-dipping from the same textual information. This is important to keep in mind for your final projects, and for a more thorough explanation and justification, you can read more about this in [Egami et al. 2018](https://arxiv.org/pdf/1802.02163.pdf).\n",
        "\n",
        "One approach to this in the Internet Arguments Corpus would be to build measures with the `pairs` that were not also `triples`. Sometimes we have excess data like this that is similar enough to our regression data, which we can use without reducing our regression sample size. For example, you could abductively generate a keyword-count measure like \"argumentativeness\" or \"thoughtfulness\" from non-triple pairs that isn't already in the annotations, and then count the keywords in the triples. You could develop an LDA model or word embedding measurement on some of the data, and the use it to establish an inferential relationship on the rest of the data. This would avoid contamination."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anRwnQMmDUlW"
      },
      "source": [
        "## <font color=\"red\">*Exercise 3*</font>\n",
        "\n",
        "<font color=\"red\">Propose a measure you could generate to fill in or improve upon the simple causal model you proposed above and how you would split the data (e.g., a % of your main data, a separate-but-informative dataset). You do not have to produce the measure.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Produce the measure and integrate it into your statistical analysis. This could be a great approach for your final project!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve my simple causal model, and based on Weibo data (containing headlines/tweet content and predicted sentiment), one possible measure is sentiment intensity. This indicator can help understand the impact of different emotional predictions (such as 'disgust', 'sad', 'trust', 'expectation', 'other', 'neutral') on user interactions (such as number of replies, emotional tendency of replies) .\n",
        "\n",
        "Data segmentation strategy\n",
        "I can split the data into training and test sets (e.g. 80% of the data for training and 20% for testing). In this way, the model can be built on the training set, and then the effect of the model can be evaluated on the test set to ensure the generalization ability of the model.\n",
        "\n",
        "achieve metrics\n",
        "Sentiment intensity measurement: I can use text analysis tools (such as sentiment analysis models) to evaluate the emotional intensity of each Weibo content. This might involve assigning a weight to each emotion prediction (for example, 'disgust' and 'sadness' might have a higher negative weight, while 'trust' and 'anticipation' might have a positive weight).\n",
        "Combined with statistical analysis\n",
        "Use regression analysis to explore how emotional intensity affects a user's level of interaction (e.g. number of replies, emotional tendencies of replies).\n",
        "Consider other potential moderator variables or confounding variables, such as the publishing time of Weibo, the influence of the author, etc."
      ],
      "metadata": {
        "id": "6onBmI0bZU-d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILgdzwrADUlW"
      },
      "source": [
        "# Text as mediator\n",
        "\n",
        "What if text is instead the _mediator_, meaning it is effected by the teatment and effects the outcome? (A moderator influences the relationship a treatment has on the outcome. This figure from [Bhandari](https://www.scribbr.com/methodology/mediator-vs-moderator/) concisely shows the difference\n",
        "\n",
        "<img src=\"https://cdn.scribbr.com/wp-content/uploads/2021/03/mediator-and-moderator-variables.png\" alt=\"https://cdn.scribbr.com/wp-content/uploads/2021/03/mediator-and-moderator-variables.png\" style=\"width:500px\">\n",
        "The moderating impact of a variable can simply be captured by in/excluding the variable alongside the purported cause of interest.)\n",
        "\n",
        "Let's briefly return to the Internet Arguments Corpus triples and model the effect of the first comment (\"quote\") on the third comment (\"response2\") mediated by the second comment (\"response1\"). Unfortunately we don't have Turker annotations for the first comment, but we can propose a simple mediation model for the propogation of comment length from first to second to third. In other words: _Is there a causal chain of comment length through a conversation?_\n",
        "\n",
        "A two-step mediation model consists of two linear models, one for each step. Let's create length_q and sentiment_q variables for our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3EpkHkxDUlX"
      },
      "outputs": [],
      "source": [
        "triples['length_q'] = triples['quote'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFXsux5lDUlX",
        "outputId": "e01ecbe5-a553-4412-cfb9-66a28951d057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 24s, sys: 185 ms, total: 2min 24s\n",
            "Wall time: 2min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "triples['sentiment_q'] = triples['quote'].apply(lambda x: sentiment(x[:512])[0]['score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0Bsp-C0DUlX"
      },
      "source": [
        "To run this analysis, statsmodel (sm) has a convenient `Mediation` module that takes in two linear models and outputs a mediation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "uY4v2qNQDUlX",
        "outputId": "8fbeafda-0bc3-433a-a437-5aeff0382a7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Estimate  Lower CI bound  Upper CI bound  P-value\n",
              "ACME (control)            0.051635       -7.504602        6.879604    0.984\n",
              "ACME (treated)            0.051635       -7.504602        6.879604    0.984\n",
              "ADE (control)             0.073303        0.020524        0.126238    0.006\n",
              "ADE (treated)             0.073303        0.020524        0.126238    0.006\n",
              "Total effect              0.124937       -7.410314        6.933450    0.964\n",
              "Prop. mediated (control)  0.993800        0.676423        1.297186    0.020\n",
              "Prop. mediated (treated)  0.993800        0.676423        1.297186    0.020\n",
              "ACME (average)            0.051635       -7.504602        6.879604    0.984\n",
              "ADE (average)             0.073303        0.020524        0.126238    0.006\n",
              "Prop. mediated (average)  0.993800        0.676423        1.297186    0.020"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13f46d10-1b5d-4ba2-a246-bcb4045509e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Estimate</th>\n",
              "      <th>Lower CI bound</th>\n",
              "      <th>Upper CI bound</th>\n",
              "      <th>P-value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ACME (control)</th>\n",
              "      <td>0.051635</td>\n",
              "      <td>-7.504602</td>\n",
              "      <td>6.879604</td>\n",
              "      <td>0.984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACME (treated)</th>\n",
              "      <td>0.051635</td>\n",
              "      <td>-7.504602</td>\n",
              "      <td>6.879604</td>\n",
              "      <td>0.984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADE (control)</th>\n",
              "      <td>0.073303</td>\n",
              "      <td>0.020524</td>\n",
              "      <td>0.126238</td>\n",
              "      <td>0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADE (treated)</th>\n",
              "      <td>0.073303</td>\n",
              "      <td>0.020524</td>\n",
              "      <td>0.126238</td>\n",
              "      <td>0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total effect</th>\n",
              "      <td>0.124937</td>\n",
              "      <td>-7.410314</td>\n",
              "      <td>6.933450</td>\n",
              "      <td>0.964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prop. mediated (control)</th>\n",
              "      <td>0.993800</td>\n",
              "      <td>0.676423</td>\n",
              "      <td>1.297186</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prop. mediated (treated)</th>\n",
              "      <td>0.993800</td>\n",
              "      <td>0.676423</td>\n",
              "      <td>1.297186</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACME (average)</th>\n",
              "      <td>0.051635</td>\n",
              "      <td>-7.504602</td>\n",
              "      <td>6.879604</td>\n",
              "      <td>0.984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADE (average)</th>\n",
              "      <td>0.073303</td>\n",
              "      <td>0.020524</td>\n",
              "      <td>0.126238</td>\n",
              "      <td>0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prop. mediated (average)</th>\n",
              "      <td>0.993800</td>\n",
              "      <td>0.676423</td>\n",
              "      <td>1.297186</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13f46d10-1b5d-4ba2-a246-bcb4045509e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13f46d10-1b5d-4ba2-a246-bcb4045509e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13f46d10-1b5d-4ba2-a246-bcb4045509e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d115faf-55b7-44dc-a46d-5a11e9c37bad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d115faf-55b7-44dc-a46d-5a11e9c37bad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d115faf-55b7-44dc-a46d-5a11e9c37bad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Mediation analysis\n",
        "y = data['预测情感']\n",
        "X_cols = ['length', '粉丝数', '评论数']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "mediator_model = sm.OLS(y,X)\n",
        "\n",
        "# For the second step of the mediation model, we can add in other predictors.\n",
        "y = triples['length_r2']\n",
        "X_cols = ['sentiment_q','length_q','fact-feeling_r1','nicenasty_r1','sarcasm_r1','length_r1','sentiment_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "outcome_model = sm.OLS(y,X)\n",
        "\n",
        "med = Mediation(outcome_model=outcome_model, mediator_model=mediator_model,\n",
        "                exposure='length_q', mediator='length_r1').fit()\n",
        "med.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekAkToHkDUlX"
      },
      "source": [
        "It looks like the Average Causal Mediated Effect (ACME) is not significantly different from zero, but the Average Direct Effect (ADE) is. This suggests that the true causal relationship here is more likely:\n",
        "\n",
        "_length_q -> length_r2_\n",
        "\n",
        "than\n",
        "\n",
        "_length_q -> length_r1 -> length_r2_\n",
        "\n",
        "What do you think explains that relationship?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsB00g9RDUlX"
      },
      "source": [
        "Once you are done with the Internet Arguments Corpus `iac_v1.1.zip` file, you may want to delete it if you are going to `git push` this directory because of [GitHub's limits on file sizes above 100 MB](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWOUtSx4DUlY"
      },
      "outputs": [],
      "source": [
        "os.remove('iac_v1.1.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUXEBmHXDUlY"
      },
      "source": [
        "## <font color=\"red\">*Exercise 4*</font>\n",
        "\n",
        "<font color=\"red\">Propose a mediation model related to the simple causal model you proposed above (ideally on the dataset you're using for your final project). If you have measures for each variable in the model, run the analysis: You can just copy the \"Mediation analysis\" cell above and replace with your variables. If you do not have measures, do not run the analysis, but be clear as to the effect(s) you would like to estimate and the research design you would use to test them."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.mediation import Mediation\n",
        "\n",
        "# 假设数据已经被加载到DataFrame中\n",
        "# 请替换'path_to_your_file.csv'为您的CSV文件的实际路径\n",
        "data = pd.read_csv('/content/predicted_shanghaidata.csv').head(300)\n",
        "\n",
        "emotion_to_num = {\n",
        "    '厌恶': 0,\n",
        "    '悲伤': 1,\n",
        "    '信任': 2,\n",
        "    '期待': 3,\n",
        "    '其他': 4,  # '其他' 包括 '愤怒', '喜悦', '恐惧', '惊讶'\n",
        "    '中性': 5\n",
        "}\n",
        "# 将特定情感分类为\"其他\"并转换为数字\n",
        "emotions_to_combine = ['愤怒', '喜悦', '恐惧', '惊讶']\n",
        "data['预测情感'] = data['预测情感'].apply(lambda x: '其他' if x in emotions_to_combine else x)\n",
        "data['预测情感'] = data['预测情感'].map(emotion_to_num)\n",
        "\n",
        "# 添加一个新列来表示微博内容的长度\n",
        "data['length'] = data['标题/微博内容'].apply(len)\n",
        "\n",
        "# 将所有的回归列转换为数值类型，并将无法转换的值设为NaN\n",
        "for column in ['预测情感', '转发数', '评论数', '点赞数', '粉丝数']:\n",
        "    data[column] = pd.to_numeric(data[column], errors='coerce')\n",
        "\n",
        "# 处理缺失值，这里简单地丢弃含有NaN的行\n",
        "data.dropna(subset=['预测情感', '转发数', '评论数', '点赞数', '粉丝数'], inplace=True)\n",
        "\n",
        "# 第一步：自变量（X）对中介变量（M）的效应\n",
        "X_med = sm.add_constant(data['粉丝数'])  # 自变量X（加上常数项）\n",
        "y_med = data['转发数']  # 中介变量M\n",
        "model_1 = sm.OLS(y_med, X_med).fit()\n",
        "a_path = model_1.params['粉丝数']\n",
        "\n",
        "# 第二步：自变量（X）对因变量（Y）的效应（总效应）\n",
        "X_out = sm.add_constant(data['粉丝数'])  # 自变量X（加上常数项）\n",
        "y_out = data['预测情感']  # 因变量Y\n",
        "model_2 = sm.OLS(y_out, X_out).fit()\n",
        "c_path = model_2.params['粉丝数']\n",
        "\n",
        "# 第三步：自变量（X）和中介变量（M）同时对因变量（Y）的效应\n",
        "X_out_med = sm.add_constant(data[['粉丝数', '转发数']])  # 自变量X和中介变量M（加上常数项）\n",
        "model_3 = sm.OLS(y_out, X_out_med).fit()\n",
        "c_prime_path = model_3.params['粉丝数']\n",
        "b_path = model_3.params['转发数']\n",
        "\n",
        "# 计算中介效应\n",
        "indirect_effect = a_path * b_path\n",
        "direct_effect = c_prime_path\n",
        "total_effect = c_path\n",
        "\n",
        "# 输出结果\n",
        "print(f\"Total effect (c path): {total_effect}\")\n",
        "print(f\"Direct effect (c' path): {direct_effect}\")\n",
        "print(f\"Indirect effect (ab paths): {indirect_effect}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXFalDh_iscD",
        "outputId": "e08464cb-2c30-4b3e-8d0c-34a5a3b7d540"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e4eb61ab8ecf>:8: DtypeWarning: Columns (0,14,17,19,20,21,22,23,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('/content/predicted_shanghaidata.csv').head(300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total effect (c path): 7.014818906172041e-07\n",
            "Direct effect (c' path): 7.098543102358392e-07\n",
            "Indirect effect (ab paths): -8.372419618634828e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSHACELUDUlY"
      },
      "source": [
        "# Text as confounder\n",
        "The causal effect we're interested in estimating might not be our causal relationship of interest. Instead, it could be another variable that affects both our treatment and outcome, known as a _confounder_. Recall the [Keith et al. 2020](https://aclanthology.org/2020.acl-main.474.pdf) figure showing the role of a confounder.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" alt=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" style=\"width:500px\">\n",
        "\n",
        "Why do we need to control for confounders? If we didn't, we might correctly find that the treatment and outcome are correlated, but rather than one causing the other, they could both be caused by a third variable. For example, if we are studying the effect of the journal a paper is published in on the citations of the paper, we may be worried that the text of the article affects both whether it is published by the journal and whether people cite it.\n",
        "\n",
        "The factors we controlled for in the Internet Arguments Corpus could be seen as confounders, but there are also specific methods to control for text confounders. As an example, we will walk through the method proposed by [Pryzant et al. (2018)](https://nlp.stanford.edu/pubs/pryzant2018lexicon.pdf).\n",
        "\n",
        "Say that we want to know the effect of product descriptions on product popularity. If I'm a shoe seller, how should I describe my shoes to maximize sales? Suppose I have data on sales of other shoes and want to learn from it:\n",
        "\n",
        "| Description   | Brand   | Sales |\n",
        "|---------------|---------|-------|\n",
        "| buy shoes !     | addidas | 15    |\n",
        "| fresh nike shoes !  | nike    | 35    |\n",
        "| nice nike shoes ! | nike    | 17    |\n",
        "\n",
        "It looks like \"nike\" is associated with higher sales! But that doesn't help me very much because I can't just advertise my shoes as Nikes. That would be incorrect and illegal (false advertising). What if we could build a lexicon of words like \"nike\" associated with certain brands and control for that in my analysis? We could then identify brand-agnostic words like \"fresh\" that have the causal effect of interest. This is the approach by Pryzant et al.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several packages that you can use for this purpose.\n",
        "\n",
        "The first is \"causal_attribution\": https://github.com/rpryzant/deconfounded-lexicon-induction\n",
        "\n",
        "The second is \"causalnlp\": https://github.com/amaiya/causalnlp\n",
        "\n",
        "Unfortunately, both packages have been created several years ago and are not compatible with default setting of google colab. But you can always downgrade the version of python and jupyter notebook first to install them, or change the source codes if you need. The codes can be found in the urls provided above.\n",
        "\n",
        "More papers for the same topic:\n",
        "https://github.com/causaltext/causal-text-papers"
      ],
      "metadata": {
        "id": "l0hZTzOfO7pe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA5FcWofDUlk"
      },
      "source": [
        "# \"Causally sufficient\" embedding and topic models\n",
        "Our final example of causal inference with text is from Victor Veitch (now a statistics and CS professor at UChicago), Sridhhar, and Blei. You may recall Blei as the lead developer of LDA, HDP, and Dynamic topic models, among other amazing contributions to content analysis.\n",
        "\n",
        "Their 2020 paper, [\"Adapting Text Embeddings for Causal Inference\"](https://arxiv.org/abs/1905.12741), proposes reducing the dimensions of contextual text embeddings (from BERT) in a manner that preserves causally relevant text signals. For example: \"Does adding a theorem to a paper affect its chance of acceptance?\" We can apply supervised dimensionality reduction to make the embedding easier to analyze (i.e., lower dimension) but preserve information about whether theorems are present. Similar to Pryzant et al., Veitch et al. have a great [GitHub respository](https://github.com/blei-lab/causal-text-embeddings) with the data and code for their paper, and their dataset of computer science papers, PeerRead, has its own great [repo](https://github.com/allenai/PeerRead).\n",
        "\n",
        "Their code is somewhat too hefty and farflung for this assignment, but for your future research, keep in mind that you can adjust your textual objects (e.g., keyword counts, topic models, word embeddings) for causal models. Bringing together unsupervised machine learning with causal inference is an exciting and rapidly developing field!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLs9WTQBDUlk"
      },
      "source": [
        "## <font color=\"red\">*Exercise 5*</font>\n",
        "\n",
        "<font color=\"red\">Pick one other paper on causal inference with text from the [\"Papers about Causal Inference and Language\n",
        "\" GitHub repository](https://github.com/causaltext/causal-text-papers). Write at least three sentences summarizing the paper and its logic of design in your own words.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Skim a few more papers. The causal world is your textual oyster!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The paper \"Text and Causal Inference: A Review of Using Text to Remove Confounding from Causal Estimates\" discusses the challenges and methodologies of using textual data to improve causal inferences in computational social science research. It addresses the problem of confounding variables in observational data and explores how text, like social media posts, can provide a rich source of information for measuring these confounders. The paper categorizes various approaches, highlights open problems in this research area, and offers guidance on the use of Natural Language Processing (NLP) to extract meaningful measurements from text, which can then be used to adjust for potential biases in causal analysis."
      ],
      "metadata": {
        "id": "jV0hHnosqs6y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EfPfX9Hqtdq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bcb9f456382b45e09f2037ed428550ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5a9927927e846be82255c68dc291075",
              "IPY_MODEL_e90eeb42968d4cfd834c08827c7fe95e",
              "IPY_MODEL_02bca7b5201748ba84aa79e097c4b833"
            ],
            "layout": "IPY_MODEL_8abbd4ab6de0475c8fe7154418525b15"
          }
        },
        "e5a9927927e846be82255c68dc291075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3aedae259134ba38e2576294e056c1b",
            "placeholder": "​",
            "style": "IPY_MODEL_ad708236ea944065b2a6aa3466b9bba9",
            "value": "config.json: 100%"
          }
        },
        "e90eeb42968d4cfd834c08827c7fe95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30d09611b8aa4b05a367f1a2a8f5389c",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17ba6c21c256439cbd641a84b65ebede",
            "value": 629
          }
        },
        "02bca7b5201748ba84aa79e097c4b833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_955ff6ddccec44bf8641198de96f4e46",
            "placeholder": "​",
            "style": "IPY_MODEL_831192cbf963447cba781bfb39d2ec3e",
            "value": " 629/629 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "8abbd4ab6de0475c8fe7154418525b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3aedae259134ba38e2576294e056c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad708236ea944065b2a6aa3466b9bba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30d09611b8aa4b05a367f1a2a8f5389c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ba6c21c256439cbd641a84b65ebede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "955ff6ddccec44bf8641198de96f4e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831192cbf963447cba781bfb39d2ec3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb8ac8bc48414fe980096f00114bfdb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_735cbc4d10c14c0a9fcad64a69447382",
              "IPY_MODEL_cd45edc660014cce843c82e6b582b5d1",
              "IPY_MODEL_1c57b3448b144d23b924bfef52c52206"
            ],
            "layout": "IPY_MODEL_1f80b2a3d4414535826b5025dfb09feb"
          }
        },
        "735cbc4d10c14c0a9fcad64a69447382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7400e647f8614d30ad788e7f741d77f5",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb6a68cff124d9888199b762166d334",
            "value": "model.safetensors: 100%"
          }
        },
        "cd45edc660014cce843c82e6b582b5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f54b79ec1f5942cf8842d7d8c410da73",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7fc4079bc2b49e9bae276d4025219ac",
            "value": 267832558
          }
        },
        "1c57b3448b144d23b924bfef52c52206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84faba4eef8f435db0e54aadf93fa517",
            "placeholder": "​",
            "style": "IPY_MODEL_57b2c18f64d04b4fa389147184aa8acb",
            "value": " 268M/268M [00:01&lt;00:00, 156MB/s]"
          }
        },
        "1f80b2a3d4414535826b5025dfb09feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7400e647f8614d30ad788e7f741d77f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb6a68cff124d9888199b762166d334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f54b79ec1f5942cf8842d7d8c410da73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7fc4079bc2b49e9bae276d4025219ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84faba4eef8f435db0e54aadf93fa517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b2c18f64d04b4fa389147184aa8acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ab733528a5247f792e2d8422c882cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13a47573af5a4677b6e104df6059b36f",
              "IPY_MODEL_29afdd1a279447d2b5ee0816783062ef",
              "IPY_MODEL_cf0e451463d94e359282f6f7335e77e7"
            ],
            "layout": "IPY_MODEL_d81bc038fe9c41c7a59a623dc4a80638"
          }
        },
        "13a47573af5a4677b6e104df6059b36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a99cec64baf544199271eb3cb073c478",
            "placeholder": "​",
            "style": "IPY_MODEL_c95cb5ce096246018a5510b2c97532bc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "29afdd1a279447d2b5ee0816783062ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39cfafcfc6764ba89c44741343194699",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b3a83d2ba8447228b8f057bc7abb580",
            "value": 48
          }
        },
        "cf0e451463d94e359282f6f7335e77e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057f71eb82084ee98c590b5bde07edc2",
            "placeholder": "​",
            "style": "IPY_MODEL_b436f5061eb444d7b47d01d7a1dfab96",
            "value": " 48.0/48.0 [00:00&lt;00:00, 763B/s]"
          }
        },
        "d81bc038fe9c41c7a59a623dc4a80638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99cec64baf544199271eb3cb073c478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c95cb5ce096246018a5510b2c97532bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39cfafcfc6764ba89c44741343194699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3a83d2ba8447228b8f057bc7abb580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "057f71eb82084ee98c590b5bde07edc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b436f5061eb444d7b47d01d7a1dfab96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787ce6cf82374df5b970f954273d027b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbfc25c5c28941428056a04448354e2f",
              "IPY_MODEL_b6a715026f7c4b31aeae2922f8f7b7cd",
              "IPY_MODEL_41550aa3ecf349adb19c4cb421e12b2c"
            ],
            "layout": "IPY_MODEL_2131109f98d34e85ba4164e70466954c"
          }
        },
        "dbfc25c5c28941428056a04448354e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3877b488ea6b4e38a6497a959a4710b8",
            "placeholder": "​",
            "style": "IPY_MODEL_08d38d813f5d4f01ad87b0d72a27183e",
            "value": "vocab.txt: 100%"
          }
        },
        "b6a715026f7c4b31aeae2922f8f7b7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_851d981f6ee34fd6859b5fffbec199b1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63551829a748456fbe759b84a8fc1ac8",
            "value": 231508
          }
        },
        "41550aa3ecf349adb19c4cb421e12b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba8474d942094866ac27fee1d3321d02",
            "placeholder": "​",
            "style": "IPY_MODEL_61a9de8ae4cd4adda85a063538f34d6d",
            "value": " 232k/232k [00:00&lt;00:00, 4.49MB/s]"
          }
        },
        "2131109f98d34e85ba4164e70466954c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3877b488ea6b4e38a6497a959a4710b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d38d813f5d4f01ad87b0d72a27183e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "851d981f6ee34fd6859b5fffbec199b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63551829a748456fbe759b84a8fc1ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba8474d942094866ac27fee1d3321d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a9de8ae4cd4adda85a063538f34d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}